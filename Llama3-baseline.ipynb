{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f8cacfa-abe9-4ba7-aacf-4a11b0fd3b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19bd5dc-7774-4cb0-b99c-b3c8d462dfc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32256a4f381e42929177cb9c9e7bc82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.1-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36516b5f-e4af-452e-9852-52870ebeaf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "from deepeval.benchmarks import HellaSwag\n",
    "from deepeval.benchmarks.tasks import HellaSwagTask\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6acc5c0-9505-4a91-8123-f436464887fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n"
     ]
    }
   ],
   "source": [
    "class Llama3(DeepEvalBaseLLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        tokenizer\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        sections = [section.strip() for section in prompt.split(\"\\n\\n\") if section.strip()]\n",
    "\n",
    "        # Take the last section, including \"Answer:\" for context\n",
    "        prompt = sections[-2]\n",
    "\n",
    "        model = self.load_model()\n",
    "\n",
    "        device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "        model_inputs = self.tokenizer([prompt], return_tensors=\"pt\").to(device)\n",
    "        model.to(device)\n",
    "\n",
    "        generated_ids = model.generate(\n",
    "            **model_inputs, \n",
    "            max_new_tokens=100, \n",
    "            use_cache=True)\n",
    "        \n",
    "        ans = self.tokenizer.batch_decode(generated_ids)[0]\n",
    "\n",
    "        match = re.search(r\"Answer:\\s*([A-D])\", ans)\n",
    "\n",
    "        if match:\n",
    "            answer = match.group(1)\n",
    "        else:\n",
    "            answer = 'N/A'\n",
    "\n",
    "        return answer\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        return self.generate(prompt)\n",
    "\n",
    "    # This is optional.\n",
    "    def batch_generate(self, promtps: list[str]) -> list[str]:\n",
    "        model = self.load_model()\n",
    "        device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "        new_p = []\n",
    "        for p in promtps:\n",
    "            sections = [section.strip() for section in prompt.split(\"\\n\\n\") if section.strip()]\n",
    "            new_p.append(sections[-2])\n",
    "            \n",
    "        model_inputs = self.tokenizer(\n",
    "            new_p,\n",
    "            padding=True,    # Ensure equal-length inputs\n",
    "            truncation=True, # Truncate inputs that exceed max_length\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\").to(device)\n",
    "        model.to(device)\n",
    "\n",
    "        generated_ids = model.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=100, use_cache=True)\n",
    "        decoded_responses = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "        res = []\n",
    "        for ans in decoded_responses:\n",
    "            match = re.search(r\"Answer:\\s*([A-D])\", ans)\n",
    "    \n",
    "            if match:\n",
    "                res.append(match.group(1))\n",
    "            else:\n",
    "                res.append('N/A')\n",
    "        return res\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"Llama 3\"\n",
    "\n",
    "\n",
    "llama3 = Llama3(model=model, tokenizer=tokenizer)\n",
    "\n",
    "test = \"\"\"\n",
    "\n",
    "The following are multiple choice questions (with answers) are sentence completion problems about Applying sunscreen.\n",
    "\n",
    "Then, the man writes over the snow covering the window of a car, and a woman wearing winter clothes smiles. then\n",
    "A., the man adds wax to the windshield and cuts it.\n",
    "B., a person board a ski lift, while two men supporting the head of the person wearing winter clothes snow as the we girls sled.\n",
    "C., the man puts on a christmas coat, knitted with netting.\n",
    "D., the man continues removing the snow on his car.\n",
    "Answer: D\n",
    "\n",
    "A female chef in white uniform shows a stack of baking pans in a large kitchen presenting them. the pans\n",
    "A. contain egg yolks and baking soda.\n",
    "B. are then sprinkled with brown sugar.\n",
    "C. are placed in a strainer on the counter.\n",
    "D. are filled with pastries and loaded into the oven.\n",
    "Answer: D\n",
    "\n",
    "The man in the center is demonstrating a hairstyle on the person wearing the blue shirt. the man in the blue shirt\n",
    "A. is standing on the sponge cutting the hair of the person wearing the blue shirt.\n",
    "B. is doing the hairstyle with his hand and the hairspray.\n",
    "C. sits on the chair next to the sink.\n",
    "D. is being shown eye to eye.\n",
    "Answer: C\n",
    "\n",
    "Two bodybuilder women are seated at a table. they\n",
    "A. are talking about diving techniques, bribing each other with muscle' n strength.\n",
    "B. are working out on exercise bikes.\n",
    "C. are arm wrestling, vieing to win.\n",
    "D. are shown on parallel bars.\n",
    "Answer: C\n",
    "\n",
    "This is a tutorial on how to start a campfire. it\n",
    "A. shows how to light the fire by rubbing a lid on it.\n",
    "B. is supposed to be a fire log, but your dad said that he might have burned it, and that if he catches fire it will hurt him.\n",
    "C. shows the campfire burning on the ground.\n",
    "D. is a green and red sweet and the recipe is to make it hot and then puts it in a pan to simmer.\n",
    "Answer: C\n",
    "\n",
    "A woman puts some lotion on her hand. She rubs the lotion onto her face. a cartoon demonstration\n",
    "A. is shown with a curling brush.\n",
    "B. is then shown of a woman crying.\n",
    "C. is shown on the screen.\n",
    "D. of a cat is shown.\n",
    "Answer:\n",
    "\n",
    "Output A, B, C, or D. Full answer not needed.\n",
    "\"\"\"\n",
    "\n",
    "# Call the generate method\n",
    "print(llama3.generate(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1e05f49-ec88-4cbc-a530-7d94c2ada56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = HellaSwag(\n",
    "    # tasks=[HellaSwagTask.APPLYING_SUNSCREEN, HellaSwagTask.SKATEBOARDING],\n",
    "    n_shots=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d734e1-c3a5-435b-97aa-8d22cb3ba199",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = benchmark.evaluate(model=llama3, batch_size = 5)\n",
    "print(\"Task-specific Scoress: \", benchmark.task_scores)\n",
    "print(\"Detailed Predictions: \", benchmark.predictions)\n",
    "print(benchmark.overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab24c010-16a1-45c9-8ae7-e4148c01db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(benchmark.predictions['Prediction'].iloc[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
