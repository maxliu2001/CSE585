{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8226c4c5-fee2-44d5-b24a-58ee7129878a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (4.46.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: deepeval in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (2.0)\n",
      "Requirement already satisfied: grpcio~=1.63.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (1.63.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc~=1.24.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (1.24.0)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (4.67.1)\n",
      "Requirement already satisfied: pytest in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (8.3.3)\n",
      "Requirement already satisfied: langchain-core in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (0.3.21)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (2.19.0)\n",
      "Requirement already satisfied: tabulate in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (0.9.0)\n",
      "Requirement already satisfied: docx2txt~=0.8 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (0.8)\n",
      "Requirement already satisfied: langchain-openai in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (0.2.10)\n",
      "Requirement already satisfied: pytest-xdist in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (3.6.1)\n",
      "Requirement already satisfied: tenacity~=8.4.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (8.4.2)\n",
      "Requirement already satisfied: ragas in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (0.2.6)\n",
      "Requirement already satisfied: opentelemetry-api~=1.24.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (1.24.0)\n",
      "Requirement already satisfied: typer in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (0.14.0)\n",
      "Requirement already satisfied: opentelemetry-sdk~=1.24.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (1.24.0)\n",
      "Requirement already satisfied: protobuf in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (4.25.5)\n",
      "Requirement already satisfied: rich in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (13.9.4)\n",
      "Requirement already satisfied: langchain in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (0.3.9)\n",
      "Requirement already satisfied: pytest-repeat in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (0.9.3)\n",
      "Requirement already satisfied: portalocker in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (3.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=6.0.2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (7.0.0)\n",
      "Requirement already satisfied: pydantic in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deepeval) (2.10.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from importlib-metadata>=6.0.2->deepeval) (3.21.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from opentelemetry-api~=1.24.0->deepeval) (1.2.15)\n",
      "Requirement already satisfied: opentelemetry-proto==1.24.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc~=1.24.0->deepeval) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.24.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc~=1.24.0->deepeval) (1.24.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc~=1.24.0->deepeval) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from opentelemetry-sdk~=1.24.0->deepeval) (0.45b0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from opentelemetry-sdk~=1.24.0->deepeval) (4.12.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain->deepeval) (2.0.35)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain->deepeval) (0.3.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain->deepeval) (3.11.8)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain->deepeval) (4.0.3)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain->deepeval) (0.1.147)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain->deepeval) (6.0.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain->deepeval) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain-core->deepeval) (24.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain-core->deepeval) (1.33)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from pydantic->deepeval) (2.27.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from pydantic->deepeval) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->deepeval) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->deepeval) (2024.7.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->deepeval) (2.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->deepeval) (3.7)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.54.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain-openai->deepeval) (1.55.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain-openai->deepeval) (0.8.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from pytest->deepeval) (1.2.2)\n",
      "Requirement already satisfied: tomli>=1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from pytest->deepeval) (2.0.1)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from pytest->deepeval) (1.5.0)\n",
      "Requirement already satisfied: iniconfig in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from pytest->deepeval) (2.0.0)\n",
      "Requirement already satisfied: execnet>=2.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from pytest-xdist->deepeval) (2.1.1)\n",
      "Requirement already satisfied: pysbd>=0.3.4 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from ragas->deepeval) (0.3.4)\n",
      "Requirement already satisfied: datasets in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from ragas->deepeval) (3.1.0)\n",
      "Requirement already satisfied: langchain-community in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from ragas->deepeval) (0.3.8)\n",
      "Requirement already satisfied: appdirs in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from ragas->deepeval) (1.4.4)\n",
      "Requirement already satisfied: nest-asyncio in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from ragas->deepeval) (1.6.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from rich->deepeval) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from rich->deepeval) (3.0.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from typer->deepeval) (1.5.4)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from typer->deepeval) (8.1.7)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (0.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (2.4.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (1.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (24.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (6.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (1.18.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api~=1.24.0->deepeval) (1.17.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->deepeval) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->deepeval) (1.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->deepeval) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->deepeval) (3.10.12)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->deepeval) (0.1.2)\n",
      "Requirement already satisfied: sniffio in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai->deepeval) (1.3.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai->deepeval) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai->deepeval) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai->deepeval) (0.8.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain->deepeval) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai->deepeval) (2024.11.6)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from datasets->ragas->deepeval) (3.16.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from datasets->ragas->deepeval) (0.3.8)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from datasets->ragas->deepeval) (0.70.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from datasets->ragas->deepeval) (0.26.3)\n",
      "Requirement already satisfied: xxhash in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from datasets->ragas->deepeval) (3.5.0)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from datasets->ragas->deepeval) (2.2.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from datasets->ragas->deepeval) (18.1.0)\n",
      "Requirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from datasets->ragas->deepeval) (2024.9.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain-community->ragas->deepeval) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain-community->ragas->deepeval) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain-community->ragas->deepeval) (2.6.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval) (3.23.1)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain->deepeval) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain->deepeval) (0.14.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas->deepeval) (1.0.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from pandas->datasets->ragas->deepeval) (2024.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from pandas->datasets->ragas->deepeval) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from pandas->datasets->ragas->deepeval) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas->deepeval) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#install deepeval and huggingface dependencies\n",
    "!pip install transformers\n",
    "!pip install -U deepeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49283fd0-8440-4a41-8a9c-835e3c540439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log into deepeval\n",
    "# do it in terminal\n",
    "# deepeval login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f95587-41ab-48f6-8262-401cf1ea2878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log into huggingface\n",
    "# huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e35dc0b9-296c-4db1-9e81-1a30c00bfabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "from deepeval.benchmarks import HellaSwag\n",
    "from deepeval.benchmarks.tasks import HellaSwagTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8082bfff-eead-4b7c-80d4-0934fdc1f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define benchmark with specific tasks and shots\n",
    "benchmark = HellaSwag(\n",
    "    tasks=[HellaSwagTask.TRIMMING_BRANCHES_OR_HEDGES, HellaSwagTask.BATON_TWIRLING],\n",
    "    n_shots=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "074aa107-f053-4344-acb6-a3e4ea44af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mistral7B(DeepEvalBaseLLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        tokenizer\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        model = self.load_model()\n",
    "\n",
    "        device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "        model_inputs = self.tokenizer([prompt], return_tensors=\"pt\").to(device)\n",
    "        model.to(device)\n",
    "\n",
    "        generated_ids = model.generate(**model_inputs, max_new_tokens=100, do_sample=True)\n",
    "        return self.tokenizer.batch_decode(generated_ids)[0]\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        model = self.load_model()\n",
    "\n",
    "        device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "        model_inputs = self.tokenizer([prompt], return_tensors=\"pt\").to(device)\n",
    "        model.to(device)\n",
    "\n",
    "        generated_ids = model.generate(**model_inputs, max_new_tokens=100, do_sample=True)\n",
    "        return self.tokenizer.batch_decode(generated_ids)[0]\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        return self.generate(prompt)\n",
    "\n",
    "    # This is optional.\n",
    "    def batch_generate(self, promtps: [str]) -> [str]:\n",
    "        model = self.load_model()\n",
    "        device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "        model_inputs = self.tokenizer(\n",
    "            promtps,\n",
    "            padding=True,    # Ensure equal-length inputs\n",
    "            truncation=True, # Truncate inputs that exceed max_length\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\").to(device)\n",
    "        model.to(device)\n",
    "\n",
    "        generated_ids = model.generate(**model_inputs, max_new_tokens=100, do_sample=True)\n",
    "        return self.tokenizer.batch_decode(generated_ids)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"Mistral 7B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b764abcd-8591-4863-82ec-800d0f549b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f4ec6ccf7764a8eaa5e148e6938a922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a379b48-068d-4b98-930f-b1a2fd672934",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_7b = Mistral7B(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1149bf16-63e0-4fcf-a425-59ba6e3c2cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Write me a joke about ______\n",
      "\n",
      "There are a million jokes about ______\n",
      "\n",
      "The more specific you are, the better\n",
      "\n",
      "The funnier it is\n",
      "\n",
      "Because that means the joke is not just about ______, but your ______.\n",
      "\n",
      "What makes you ______?\n",
      "\n",
      "What makes you unique to the world?\n",
      "\n",
      "Write about this.\n",
      "\n",
      "Write about this with a hearty laugh.\n",
      "\n",
      "Because while you cannot change yourself, it is only in\n"
     ]
    }
   ],
   "source": [
    "print(mistral_7b.generate(\"Write me a joke\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d25aef9-c3ca-4fb2-a2ab-11cbde01127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Trimming branches or hedges:   0%|          | 0/4 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Trimming branches or hedges:  25%|██▌       | 1/4 [00:04<00:14,  4.93s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Trimming branches or hedges:  50%|█████     | 2/4 [00:05<00:04,  2.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Trimming branches or hedges:  75%|███████▌  | 3/4 [00:10<00:03,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Trimming branches or hedges: 100%|██████████| 4/4 [00:15<00:00,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HellaSwag Task Accuracy (task=Trimming branches or hedges): 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ba0d61c8e744b0b44dee829923d4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Baton twirling:   0%|          | 0/14 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:   7%|▋         | 1/14 [00:04<01:01,  4.76s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  14%|█▍        | 2/14 [00:08<00:49,  4.13s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  21%|██▏       | 3/14 [00:13<00:49,  4.48s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  29%|██▊       | 4/14 [00:18<00:45,  4.58s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  36%|███▌      | 5/14 [00:22<00:41,  4.65s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  43%|████▎     | 6/14 [00:24<00:28,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  50%|█████     | 7/14 [00:24<00:18,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  57%|█████▋    | 8/14 [00:29<00:19,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  64%|██████▍   | 9/14 [00:34<00:18,  3.74s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  71%|███████▏  | 10/14 [00:39<00:16,  4.08s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  79%|███████▊  | 11/14 [00:44<00:12,  4.29s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  86%|████████▌ | 12/14 [00:48<00:08,  4.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  93%|█████████▎| 13/14 [00:49<00:03,  3.26s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling: 100%|██████████| 14/14 [00:54<00:00,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HellaSwag Task Accuracy (task=Baton twirling): 0.0\n",
      "Overall HellaSwag Accuracy: 0.0\n",
      "Task-specific Scores:                            Task  Score\n",
      "0  Trimming branches or hedges    0.0\n",
      "1               Baton twirling    0.0\n",
      "Detailed Predictions:                             Task  \\\n",
      "0   Trimming branches or hedges   \n",
      "1   Trimming branches or hedges   \n",
      "2   Trimming branches or hedges   \n",
      "3   Trimming branches or hedges   \n",
      "4                Baton twirling   \n",
      "5                Baton twirling   \n",
      "6                Baton twirling   \n",
      "7                Baton twirling   \n",
      "8                Baton twirling   \n",
      "9                Baton twirling   \n",
      "10               Baton twirling   \n",
      "11               Baton twirling   \n",
      "12               Baton twirling   \n",
      "13               Baton twirling   \n",
      "14               Baton twirling   \n",
      "15               Baton twirling   \n",
      "16               Baton twirling   \n",
      "17               Baton twirling   \n",
      "\n",
      "                                                Input  \\\n",
      "0   A man is shown working in an outdoor garden. h...   \n",
      "1   A man is standing outside turning on his hedge...   \n",
      "2   A man has climbed a large ladder outside. he\\n...   \n",
      "3   A man has climbed a large ladder outside. He i...   \n",
      "4   A young girl in a green leotard begins twirlin...   \n",
      "5   The girl begins to incorporate her arms and do...   \n",
      "6   As the young lady continues her performance, s...   \n",
      "7   A couple of girls are on a gym court. they\\nA....   \n",
      "8   In a gym a baton twirling troupe walk into a g...   \n",
      "9   The music begins and the girls do their routin...   \n",
      "10  The news announcer is commenting on the events...   \n",
      "11  A baton twirler is standing on the gym floor. ...   \n",
      "12  Then, the young man spins the stick on his nec...   \n",
      "13  She is dancing next a large drum wheel while b...   \n",
      "14  We see a girl in gold doing a baton routine. T...   \n",
      "15  The girls spins repeatedly and catches her bat...   \n",
      "16  Cheerleader team are holding batons doing a ch...   \n",
      "17  A large group of people are seen standing arou...   \n",
      "\n",
      "                                           Prediction  Correct  \n",
      "0   <s> The following are multiple choice question...        0  \n",
      "1   <s> The following are multiple choice question...        0  \n",
      "2   <s> The following are multiple choice question...        0  \n",
      "3   <s> The following are multiple choice question...        0  \n",
      "4   <s> The following are multiple choice question...        0  \n",
      "5   <s> The following are multiple choice question...        0  \n",
      "6   <s> The following are multiple choice question...        0  \n",
      "7   <s> The following are multiple choice question...        0  \n",
      "8   <s> The following are multiple choice question...        0  \n",
      "9   <s> The following are multiple choice question...        0  \n",
      "10  <s> The following are multiple choice question...        0  \n",
      "11  <s> The following are multiple choice question...        0  \n",
      "12  <s> The following are multiple choice question...        0  \n",
      "13  <s> The following are multiple choice question...        0  \n",
      "14  <s> The following are multiple choice question...        0  \n",
      "15  <s> The following are multiple choice question...        0  \n",
      "16  <s> The following are multiple choice question...        0  \n",
      "17  <s> The following are multiple choice question...        0  \n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = benchmark.evaluate(model=mistral_7b, batch_size=10)\n",
    "print(\"Task-specific Scores: \", benchmark.task_scores)\n",
    "print(\"Detailed Predictions: \", benchmark.predictions)\n",
    "print(benchmark.overall_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
