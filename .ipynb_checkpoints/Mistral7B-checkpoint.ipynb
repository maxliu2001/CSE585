{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8226c4c5-fee2-44d5-b24a-58ee7129878a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Downloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 kB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m114.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, tokenizers, transformers\n",
      "Successfully installed safetensors-0.4.5 tokenizers-0.20.1 transformers-4.45.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: deepeval in /opt/conda/lib/python3.10/site-packages (1.4.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from deepeval) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from deepeval) (4.66.5)\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from deepeval) (8.3.3)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from deepeval) (0.9.0)\n",
      "Requirement already satisfied: typer in /opt/conda/lib/python3.10/site-packages (from deepeval) (0.12.5)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from deepeval) (13.9.2)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from deepeval) (4.25.5)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from deepeval) (2.9.2)\n",
      "Requirement already satisfied: sentry-sdk in /opt/conda/lib/python3.10/site-packages (from deepeval) (2.17.0)\n",
      "Requirement already satisfied: pytest-repeat in /opt/conda/lib/python3.10/site-packages (from deepeval) (0.9.3)\n",
      "Requirement already satisfied: pytest-xdist in /opt/conda/lib/python3.10/site-packages (from deepeval) (3.6.1)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.10/site-packages (from deepeval) (2.10.1)\n",
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (from deepeval) (0.3.4)\n",
      "Requirement already satisfied: langchain-core in /opt/conda/lib/python3.10/site-packages (from deepeval) (0.3.12)\n",
      "Requirement already satisfied: langchain-openai in /opt/conda/lib/python3.10/site-packages (from deepeval) (0.2.3)\n",
      "Requirement already satisfied: ragas in /opt/conda/lib/python3.10/site-packages (from deepeval) (0.2.1)\n",
      "Requirement already satisfied: docx2txt~=0.8 in /opt/conda/lib/python3.10/site-packages (from deepeval) (0.8)\n",
      "Requirement already satisfied: importlib-metadata>=6.0.2 in /opt/conda/lib/python3.10/site-packages (from deepeval) (7.0.0)\n",
      "Requirement already satisfied: tenacity~=8.4.1 in /opt/conda/lib/python3.10/site-packages (from deepeval) (8.4.2)\n",
      "Requirement already satisfied: opentelemetry-api~=1.24.0 in /opt/conda/lib/python3.10/site-packages (from deepeval) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-sdk~=1.24.0 in /opt/conda/lib/python3.10/site-packages (from deepeval) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc~=1.24.0 in /opt/conda/lib/python3.10/site-packages (from deepeval) (1.24.0)\n",
      "Requirement already satisfied: grpcio~=1.63.0 in /opt/conda/lib/python3.10/site-packages (from deepeval) (1.63.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=6.0.2->deepeval) (3.20.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api~=1.24.0->deepeval) (1.2.14)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc~=1.24.0->deepeval) (1.65.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.24.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc~=1.24.0->deepeval) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.24.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc~=1.24.0->deepeval) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-sdk~=1.24.0->deepeval) (0.45b0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-sdk~=1.24.0->deepeval) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain->deepeval) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain->deepeval) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain->deepeval) (3.10.10)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain->deepeval) (4.0.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from langchain->deepeval) (0.3.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain->deepeval) (0.1.136)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain->deepeval) (1.26.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core->deepeval) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core->deepeval) (24.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic->deepeval) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic->deepeval) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->deepeval) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->deepeval) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->deepeval) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->deepeval) (2023.11.17)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.52.0 in /opt/conda/lib/python3.10/site-packages (from langchain-openai->deepeval) (1.52.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/conda/lib/python3.10/site-packages (from langchain-openai->deepeval) (0.8.0)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->deepeval) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /opt/conda/lib/python3.10/site-packages (from pytest->deepeval) (1.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest->deepeval) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1 in /opt/conda/lib/python3.10/site-packages (from pytest->deepeval) (2.0.1)\n",
      "Requirement already satisfied: execnet>=2.1 in /opt/conda/lib/python3.10/site-packages (from pytest-xdist->deepeval) (2.1.1)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from ragas->deepeval) (3.0.1)\n",
      "Requirement already satisfied: langchain-community in /opt/conda/lib/python3.10/site-packages (from ragas->deepeval) (0.3.3)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from ragas->deepeval) (1.6.0)\n",
      "Requirement already satisfied: appdirs in /opt/conda/lib/python3.10/site-packages (from ragas->deepeval) (1.4.4)\n",
      "Requirement already satisfied: pysbd>=0.3.4 in /opt/conda/lib/python3.10/site-packages (from ragas->deepeval) (0.3.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->deepeval) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->deepeval) (2.15.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer->deepeval) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer->deepeval) (1.5.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (1.16.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api~=1.24.0->deepeval) (1.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->deepeval) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->deepeval) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->deepeval) (3.10.9)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->deepeval) (1.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->deepeval) (0.1.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.52.0->langchain-openai->deepeval) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.52.0->langchain-openai->deepeval) (1.8.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.52.0->langchain-openai->deepeval) (0.6.1)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.52.0->langchain-openai->deepeval) (1.3.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain->deepeval) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai->deepeval) (2024.9.11)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets->ragas->deepeval) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->ragas->deepeval) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->ragas->deepeval) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->ragas->deepeval) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->ragas->deepeval) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->ragas->deepeval) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->ragas->deepeval) (2023.12.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets->ragas->deepeval) (0.26.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community->ragas->deepeval) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community->ragas->deepeval) (2.6.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval) (3.23.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval) (0.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain->deepeval) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain->deepeval) (0.14.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas->deepeval) (1.0.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (0.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->ragas->deepeval) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->ragas->deepeval) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->ragas->deepeval) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas->deepeval) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval) (1.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#install deepeval and huggingface dependencies\n",
    "!pip install transformers\n",
    "!pip install -U deepeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49283fd0-8440-4a41-8a9c-835e3c540439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log into deepeval\n",
    "# do it in terminal\n",
    "# deepeval login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f95587-41ab-48f6-8262-401cf1ea2878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log into huggingface\n",
    "# huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35dc0b9-296c-4db1-9e81-1a30c00bfabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "from deepeval.benchmarks import HellaSwag\n",
    "from deepeval.benchmarks.tasks import HellaSwagTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8082bfff-eead-4b7c-80d4-0934fdc1f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define benchmark with specific tasks and shots\n",
    "benchmark = HellaSwag(\n",
    "    tasks=[HellaSwagTask.TRIMMING_BRANCHES_OR_HEDGES, HellaSwagTask.BATON_TWIRLING],\n",
    "    n_shots=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "074aa107-f053-4344-acb6-a3e4ea44af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mistral7B(DeepEvalBaseLLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        tokenizer\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        model = self.load_model()\n",
    "\n",
    "        device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "        model_inputs = self.tokenizer([prompt], return_tensors=\"pt\").to(device)\n",
    "        model.to(device)\n",
    "\n",
    "        generated_ids = model.generate(**model_inputs, max_new_tokens=100, do_sample=True)\n",
    "        return self.tokenizer.batch_decode(generated_ids)[0]\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        return self.generate(prompt)\n",
    "\n",
    "    # This is optional.\n",
    "    def batch_generate(self, prompts: list[str]) -> list[str]:\n",
    "        model = self.load_model()\n",
    "        device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "        model_inputs = self.tokenizer(promtps, return_tensors=\"pt\").to(device)\n",
    "        model.to(device)\n",
    "\n",
    "        generated_ids = model.generate(**model_inputs, max_new_tokens=100, do_sample=True)\n",
    "        return self.tokenizer.batch_decode(generated_ids)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"Mistral 7B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b764abcd-8591-4863-82ec-800d0f549b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05de531e5154ec2a936294a3fca3cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b9af83cc664cfe866bf00723bdf993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df4f1aa2d1d435d809154964802177d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd55e9cff0949db87de42a4936471bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc07b02753b4473b3746f4610b32fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773c0a3177ca4da1a75ccc769591ddd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4409460ab0bc48a3a3133657ab4c85ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3834da6ae4284220ae948995e47e2bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a379b48-068d-4b98-930f-b1a2fd672934",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_7b = Mistral7B(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1149bf16-63e0-4fcf-a425-59ba6e3c2cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Write me a jokeGenerate only one letter choice for the following word:\n",
      "\n",
      "loath \\_ o _ th\n",
      "\n",
      "Theletter is h. The correct answer is \"loath\" is an archaic word that means to feel intense aversion or dislike, and the correct spelling is \"loath\". However, due to its similarity to \"laugh\" and the context of the prompt, the most common mistake is to add an \"h\" at the beginning, creating the incorrect word \"loathing\" which\n"
     ]
    }
   ],
   "source": [
    "print(mistral_7b.generate(\"Write me a joke\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d25aef9-c3ca-4fb2-a2ab-11cbde01127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Trimming branches or hedges:   0%|          | 0/4 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Trimming branches or hedges:  25%|██▌       | 1/4 [00:03<00:11,  3.89s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Trimming branches or hedges:  50%|█████     | 2/4 [00:04<00:04,  2.05s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Trimming branches or hedges:  75%|███████▌  | 3/4 [00:09<00:03,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Trimming branches or hedges: 100%|██████████| 4/4 [00:13<00:00,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HellaSwag Task Accuracy (task=Trimming branches or hedges): 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Baton twirling:   0%|          | 0/14 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:   7%|▋         | 1/14 [00:04<00:56,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  14%|█▍        | 2/14 [00:08<00:52,  4.40s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  21%|██▏       | 3/14 [00:13<00:48,  4.41s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  29%|██▊       | 4/14 [00:17<00:43,  4.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  36%|███▌      | 5/14 [00:21<00:39,  4.40s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  43%|████▎     | 6/14 [00:26<00:35,  4.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  50%|█████     | 7/14 [00:30<00:30,  4.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  57%|█████▋    | 8/14 [00:32<00:22,  3.68s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  64%|██████▍   | 9/14 [00:37<00:19,  3.90s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  71%|███████▏  | 10/14 [00:39<00:13,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  79%|███████▊  | 11/14 [00:44<00:11,  3.77s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  86%|████████▌ | 12/14 [00:45<00:05,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling:  93%|█████████▎| 13/14 [00:49<00:03,  3.32s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Baton twirling: 100%|██████████| 14/14 [00:52<00:00,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HellaSwag Task Accuracy (task=Baton twirling): 0.0\n",
      "Overall HellaSwag Accuracy: 0.0\n",
      "Task-specific Scores:                            Task  Score\n",
      "0  Trimming branches or hedges    0.0\n",
      "1               Baton twirling    0.0\n",
      "Detailed Predictions:                             Task  \\\n",
      "0   Trimming branches or hedges   \n",
      "1   Trimming branches or hedges   \n",
      "2   Trimming branches or hedges   \n",
      "3   Trimming branches or hedges   \n",
      "4                Baton twirling   \n",
      "5                Baton twirling   \n",
      "6                Baton twirling   \n",
      "7                Baton twirling   \n",
      "8                Baton twirling   \n",
      "9                Baton twirling   \n",
      "10               Baton twirling   \n",
      "11               Baton twirling   \n",
      "12               Baton twirling   \n",
      "13               Baton twirling   \n",
      "14               Baton twirling   \n",
      "15               Baton twirling   \n",
      "16               Baton twirling   \n",
      "17               Baton twirling   \n",
      "\n",
      "                                                Input  \\\n",
      "0   A man is shown working in an outdoor garden. h...   \n",
      "1   A man is standing outside turning on his hedge...   \n",
      "2   A man has climbed a large ladder outside. he\\n...   \n",
      "3   A man has climbed a large ladder outside. He i...   \n",
      "4   A young girl in a green leotard begins twirlin...   \n",
      "5   The girl begins to incorporate her arms and do...   \n",
      "6   As the young lady continues her performance, s...   \n",
      "7   A couple of girls are on a gym court. they\\nA....   \n",
      "8   In a gym a baton twirling troupe walk into a g...   \n",
      "9   The music begins and the girls do their routin...   \n",
      "10  The news announcer is commenting on the events...   \n",
      "11  A baton twirler is standing on the gym floor. ...   \n",
      "12  Then, the young man spins the stick on his nec...   \n",
      "13  She is dancing next a large drum wheel while b...   \n",
      "14  We see a girl in gold doing a baton routine. T...   \n",
      "15  The girls spins repeatedly and catches her bat...   \n",
      "16  Cheerleader team are holding batons doing a ch...   \n",
      "17  A large group of people are seen standing arou...   \n",
      "\n",
      "                                           Prediction  Correct  \n",
      "0   <s> The following are multiple choice question...        0  \n",
      "1   <s> The following are multiple choice question...        0  \n",
      "2   <s> The following are multiple choice question...        0  \n",
      "3   <s> The following are multiple choice question...        0  \n",
      "4   <s> The following are multiple choice question...        0  \n",
      "5   <s> The following are multiple choice question...        0  \n",
      "6   <s> The following are multiple choice question...        0  \n",
      "7   <s> The following are multiple choice question...        0  \n",
      "8   <s> The following are multiple choice question...        0  \n",
      "9   <s> The following are multiple choice question...        0  \n",
      "10  <s> The following are multiple choice question...        0  \n",
      "11  <s> The following are multiple choice question...        0  \n",
      "12  <s> The following are multiple choice question...        0  \n",
      "13  <s> The following are multiple choice question...        0  \n",
      "14  <s> The following are multiple choice question...        0  \n",
      "15  <s> The following are multiple choice question...        0  \n",
      "16  <s> The following are multiple choice question...        0  \n",
      "17  <s> The following are multiple choice question...        0  \n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = benchmark.evaluate(model=mistral_7b, batch_size=5)\n",
    "print(\"Task-specific Scores: \", benchmark.task_scores)\n",
    "print(\"Detailed Predictions: \", benchmark.predictions)\n",
    "print(benchmark.overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab9634f-0419-45a7-8c0c-155558005d15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
