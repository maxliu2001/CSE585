{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e575ab-cf73-4817-b2ed-d49f4895cf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"garage-bAInd/Open-Platypus\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "839b1c07-2369-40ed-97b9-a5a961e32e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install -q -U datasets scipy ipywidgets matplotlib einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c877fe79-0f71-4b94-b09b-770f9c4b6811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 19940\n",
      "Validation set size: 4986\n"
     ]
    }
   ],
   "source": [
    "train_val_split = ds.train_test_split(test_size=0.2)\n",
    "\n",
    "# Extract the training and validation datasets\n",
    "train_dataset = train_val_split['train']\n",
    "val_dataset = train_val_split['test']\n",
    "\n",
    "# Print the size of the datasets\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f39ec1a0-c645-4844-a90a-63ca75390652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    text = f\"### Question: {example['instruction']}\\n ### Answer: {example['output']}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "072d7438-2463-45d0-a966-88164372d95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Question: A board game spinner is divided into three parts labeled $A$, $B$  and $C$. The probability of the spinner landing on $A$ is $\\frac{1}{3}$ and the probability of the spinner landing on $B$ is $\\frac{5}{12}$.  What is the probability of the spinner landing on $C$? Express your answer as a common fraction.\n",
      " ### Answer: To find the probability of the spinner landing on $C$, I need to subtract the probabilities of the spinner landing on $A$ and $B$ from $1$, since the sum of the probabilities of all possible outcomes is $1$. I can write this as an equation: $P(C) = 1 - P(A) - P(B)$. I know that $P(A) = \\frac{1}{3}$ and $P(B) = \\frac{5}{12}$, so I can plug those values into the equation and simplify. I get: $P(C) = 1 - \\frac{1}{3} - \\frac{5}{12} = \\frac{12}{12} - \\frac{4}{12} - \\frac{5}{12} = \\frac{3}{12}$. I can reduce this fraction by dividing the numerator and denominator by $3$, and I get: $P(C) = \\frac{1}{4}$. \n"
     ]
    }
   ],
   "source": [
    "print(formatting_func(ds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f66eacb-57ac-491f-9a92-781df1cbea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2d925a1-826b-4770-b927-6d5d2959c0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4603c0ffcf0a427e9cda5988bf6d7b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_id = \"meta-llama/Llama-3.1-8B\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "23e7b922-4247-4a61-9884-9131c6acfb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    "    use_fast=False, # needed for now, should be fixed soon\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "67a62421-7e3e-43df-8f06-e1c895644579",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 2048 # This was an appropriate max length for my dataset\n",
    "\n",
    "def generate_and_tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        formatting_func(prompt),\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8538973d-1c01-48ce-93fe-fb071b0f52be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac48d56f72b4905a5ad18befca84b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19940 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7335e6f67040079f51f3992989ecc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4986 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\n",
    "tokenized_val_dataset = val_dataset.map(generate_and_tokenize_prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b9c5e8e7-4327-4995-93ad-03e47665f838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24926\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2QAAAIjCAYAAABswtioAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABOYElEQVR4nO3de3zP9f//8ft7mx2MbU7bLGvkPOccF4kaw1Kir0PUiHzUlFMlJYfKxydFSOhoqZRUVMqYOZVUiETOZ9nMh7aZtLG9fn/02+vjbcM24zl2u14u78vH+/l6vF+vx+u1F+v+eb1ez7fDsixLAAAAAIBrzsV0AwAAAABQXBHIAAAAAMAQAhkAAAAAGEIgAwAAAABDCGQAAAAAYAiBDAAAAAAMIZABAAAAgCEEMgAAAAAwhEAGAAAAAIYQyACgEIwbN04Oh+OabKtNmzZq06aN/X7VqlVyOBz67LPPrsn2+/btq8qVK1+TbRVUWlqaBgwYoMDAQDkcDg0dOtR0S4XuWv/cLyc2NlYNGzaUp6enHA6HkpOTc62LiYmRw+HQgQMHrml/V0N+9qVy5crq27fvVe8JwPWHQAYAF8j+j6zsl6enp4KCghQREaHp06fr1KlThbKdo0ePaty4cdq8eXOhrK8wFeXe8uLf//63YmJi9Oijj+qDDz7Qgw8+eNHaypUr6+67776G3eXPvHnzNHXqVNNtXNKJEyfUvXt3eXl56Y033tAHH3wgb29v023lye+//65x48bdEAERwPXJzXQDAFBUvfDCC6pSpYrOnj2rxMRErVq1SkOHDtWUKVP01VdfqX79+nbt6NGj9cwzz+Rr/UePHtX48eNVuXJlNWzYMM+fW7ZsWb62UxCX6u3tt99WVlbWVe/hSqxYsUItWrTQ2LFjTbdyxebNm6etW7cW6at869ev16lTp/Tiiy8qPDz8krUPPvigevbsKQ8Pj2vU3aX9/vvvGj9+vNq0aZPvK79FbV8AXJ8IZABwER07dlSTJk3s96NGjdKKFSt0991365577tH27dvl5eUlSXJzc5Ob29X9J/Wvv/5SyZIl5e7uflW3czklSpQwuv28SEpKUmhoqOk2io2kpCRJkp+f32VrXV1d5erqepU7ujZupH0BYA63LAJAPtx55516/vnndfDgQX344Yf2eG7PkMXFxalVq1by8/NTqVKlVLNmTT377LOS/nn+p2nTppKkfv362bdHxsTESPrnObG6detq48aNat26tUqWLGl/9sJnyLJlZmbq2WefVWBgoLy9vXXPPffo8OHDTjUXe47l/HVerrfcniE7ffq0RowYoeDgYHl4eKhmzZp69dVXZVmWU53D4dDgwYO1aNEi1a1bVx4eHqpTp45iY2NzP+AXSEpKUv/+/RUQECBPT081aNBA77//vr08+7mq/fv365tvvrF7L4zb0T788EM1btxYXl5eKlu2rHr27Jnj+Gb/3H7//Xe1bdtWJUuW1E033aRJkyblWN/Bgwd1zz33yNvbW/7+/ho2bJiWLl0qh8OhVatW2ev75ptvdPDgQXtfLjz2WVlZmjBhgipVqiRPT0/ddddd2rNnj1PN7t271a1bNwUGBsrT01OVKlVSz549lZKSctn9XrBggb3f5cuXV58+ffTHH3847XNUVJQkqWnTpnI4HJd8Viq3566ybxv9/vvv1axZM3l6euqWW27R3Llzc/3smjVr9K9//UvlypWTj4+PHnroIf35559OtQ6HQ+PGjcux/fP/DsTExOj//u//JElt27a1j3H28b+c3PbFsiy99NJLqlSpkkqWLKm2bdtq27ZtOT579uxZjR8/XtWrV5enp6fKlSunVq1aKS4uLk/bBnDj4AoZAOTTgw8+qGeffVbLli3TI488kmvNtm3bdPfdd6t+/fp64YUX5OHhoT179mjt2rWSpNq1a+uFF17QmDFjNHDgQN1+++2SpNtuu81ex4kTJ9SxY0f17NlTffr0UUBAwCX7mjBhghwOh0aOHKmkpCRNnTpV4eHh2rx5s30lLy/y0tv5LMvSPffco5UrV6p///5q2LChli5dqqeeekp//PGHXnvtNaf677//Xl988YUee+wxlS5dWtOnT1e3bt106NAhlStX7qJ9nTlzRm3atNGePXs0ePBgValSRQsWLFDfvn2VnJysIUOGqHbt2vrggw80bNgwVapUSSNGjJAkVahQIc/7n5sJEybo+eefV/fu3TVgwAAdP35cr7/+ulq3bq1NmzY5XRn6888/1aFDB3Xt2lXdu3fXZ599ppEjR6pevXrq2LGjpH8C7J133qmEhAQNGTJEgYGBmjdvnlauXOm03eeee04pKSk6cuSIfRxLlSrlVPOf//xHLi4uevLJJ5WSkqJJkyapd+/e+umnnyRJGRkZioiIUHp6uh5//HEFBgbqjz/+0OLFi5WcnCxfX9+L7ndMTIz69eunpk2bauLEiTp27JimTZumtWvX2vv93HPPqWbNmnrrrbfs23yrVq2a72O8Z88e3X///erfv7+ioqL03nvvqW/fvmrcuLHq1KnjVDt48GD5+flp3Lhx2rlzp2bNmqWDBw/agTyvWrdurSeeeELTp0/Xs88+q9q1a0uS/b8FMWbMGL300kvq1KmTOnXqpF9++UXt27dXRkaGU924ceM0ceJEDRgwQM2aNVNqaqo2bNigX375Re3atSvw9gFchywAgJM5c+ZYkqz169dftMbX19dq1KiR/X7s2LHW+f+kvvbaa5Yk6/jx4xddx/r16y1J1pw5c3Isu+OOOyxJ1uzZs3Nddscdd9jvV65caUmybrrpJis1NdUe//TTTy1J1rRp0+yxkJAQKyoq6rLrvFRvUVFRVkhIiP1+0aJFliTrpZdecqq7//77LYfDYe3Zs8cek2S5u7s7jf3666+WJOv111/Psa3zTZ061ZJkffjhh/ZYRkaGFRYWZpUqVcpp30NCQqzIyMhLri+vtQcOHLBcXV2tCRMmOI3/9ttvlpubm9N49s9t7ty59lh6eroVGBhodevWzR6bPHmyJclatGiRPXbmzBmrVq1aliRr5cqV9nhkZKTT8c6W/XOvXbu2lZ6ebo9PmzbNkmT99ttvlmVZ1qZNmyxJ1oIFCy5/MM6TkZFh+fv7W3Xr1rXOnDljjy9evNiSZI0ZM8Yey8vfmQtr9+/fb4+FhIRYkqw1a9bYY0lJSZaHh4c1YsSIHJ9t3LixlZGRYY9PmjTJkmR9+eWX9pgka+zYsTm2f+HfgQULFuQ45nl14b4kJSVZ7u7uVmRkpJWVlWXXPfvss5Ykp+02aNAgz+cogBsbtywCQAGUKlXqkrMtZl8x+fLLLws8AYaHh4f69euX5/qHHnpIpUuXtt/ff//9qlixor799tsCbT+vvv32W7m6uuqJJ55wGh8xYoQsy9KSJUucxsPDw52uoNSvX18+Pj7at2/fZbcTGBioXr162WMlSpTQE088obS0NK1evboQ9ianL774QllZWerevbv++9//2q/AwEBVr149x1WtUqVKqU+fPvZ7d3d3NWvWzGn/YmNjddNNN+mee+6xxzw9PS96xfVS+vXr5/RcYfYVzeztZV8BW7p0qf766688r3fDhg1KSkrSY489Jk9PT3s8MjJStWrV0jfffJPvXi8lNDTU7l3656pmzZo1cz0vBg4c6PQs46OPPio3N7erfq5fzvLly5WRkaHHH3/c6UpdbhOy+Pn5adu2bdq9e/c17BBAUUQgA4ACSEtLcwo/F+rRo4datmypAQMGKCAgQD179tSnn36ar3B200035WsCj+rVqzu9dzgcqlat2lWfzvvgwYMKCgrKcTyyb/s6ePCg0/jNN9+cYx1lypTJ8QxQbtupXr26XFycf3VdbDuFZffu3bIsS9WrV1eFChWcXtu3b7cntMhWqVKlHLfNXbh/Bw8eVNWqVXPUVatWLd/9XXg8y5QpI0n29qpUqaLhw4frnXfeUfny5RUREaE33njjss+PZR/PmjVr5lhWq1atQj/e+TkvLjzXS5UqpYoVKxqfuj77mFzYX4UKFeyfS7YXXnhBycnJqlGjhurVq6ennnpKW7ZsuWa9Aig6CGQAkE9HjhxRSkrKJf/j2cvLS2vWrNHy5cv14IMPasuWLerRo4fatWunzMzMPG0nP8995dXFnq/Ja0+F4WKz0lkXTABSVGRlZcnhcCg2NlZxcXE5Xm+++aZT/bXev7xsb/LkydqyZYueffZZnTlzRk888YTq1KmjI0eOXJWeCuJaHbdrea5fSuvWrbV371699957qlu3rt555x3deuuteuedd0y3BuAaI5ABQD598MEHkqSIiIhL1rm4uOiuu+7SlClT9Pvvv2vChAlasWKFfYtbfiYfyIsLb32yLEt79uxxmpWvTJkySk5OzvHZC6925Ke3kJAQHT16NMctnDt27LCXF4aQkBDt3r07x1XGwt7OhapWrSrLslSlShWFh4fneLVo0SLf6wwJCdHevXtzhI0LZ0eUCu88qVevnkaPHq01a9bou+++0x9//KHZs2dfskdJ2rlzZ45lO3fuvGrHOy8uPNfT0tKUkJBw2XM9IyNDCQkJTmOF+fcw+5hc2N/x48dzvdJXtmxZ9evXTx9//LEOHz6s+vXr5zozJIAbG4EMAPJhxYoVevHFF1WlShX17t37onUnT57MMZb9Bcvp6emSJG9vb0nKNSAVxNy5c51C0WeffaaEhAR7Zj/pn3Dx448/Os34tnjx4hzTt+ent06dOikzM1MzZsxwGn/ttdfkcDictn8lOnXqpMTERM2fP98eO3funF5//XWVKlVKd9xxR6Fs50Jdu3aVq6urxo8fnyNAWZalEydO5HudERER+uOPP/TVV1/ZY3///bfefvvtHLXe3t55mp7+YlJTU3Xu3DmnsXr16snFxcU+F3PTpEkT+fv7a/bs2U51S5Ys0fbt2xUZGVngnq7UW2+9pbNnz9rvZ82apXPnzuU419esWZPjcxdeISvMv4fh4eEqUaKEXn/9dadzZerUqTlqLzxvSpUqpWrVql3yZwLgxsS09wBwEUuWLNGOHTt07tw5HTt2TCtWrFBcXJxCQkL01VdfOU10cKEXXnhBa9asUWRkpEJCQpSUlKSZM2eqUqVKatWqlaR//oPRz89Ps2fPVunSpeXt7a3mzZurSpUqBeq3bNmyatWqlfr166djx45p6tSpqlatmtNEEQMGDNBnn32mDh06qHv37tq7d68+/PDDHNOU56e3zp07q23btnruued04MABNWjQQMuWLdOXX36poUOHFmgK9NwMHDhQb775pvr27auNGzeqcuXK+uyzz7R27VpNnTr1ks/0Xc6ePXv00ksv5Rhv1KiRIiMj9dJLL2nUqFE6cOCAunTpotKlS2v//v1auHChBg4cqCeffDJf2/vXv/6lGTNmqFevXhoyZIgqVqyojz76yD6nzr9q07hxY82fP1/Dhw9X06ZNVapUKXXu3DnP21qxYoUGDx6s//u//1ONGjV07tw5ffDBB3J1dVW3bt0u+rkSJUro5ZdfVr9+/XTHHXeoV69e9rT3lStX1rBhw/K1z4UpIyNDd911l7p3766dO3dq5syZatWqldMkKQMGDNCgQYPUrVs3tWvXTr/++quWLl2q8uXLO62rYcOGcnV11csvv6yUlBR5eHjozjvvlL+/f777qlChgp588klNnDhRd999tzp16qRNmzZpyZIlObYbGhqqNm3aqHHjxipbtqw2bNigzz77TIMHDy7YQQFw/TIzuSMAFF3ZU1lnv9zd3a3AwECrXbt21rRp05ymV8924bT38fHx1r333msFBQVZ7u7uVlBQkNWrVy9r165dTp/78ssvrdDQUMvNzc1pmvk77rjDqlOnTq79XWza+48//tgaNWqU5e/vb3l5eVmRkZHWwYMHc3x+8uTJ1k033WR5eHhYLVu2tDZs2JBjnZfq7cJp7y3Lsk6dOmUNGzbMCgoKskqUKGFVr17deuWVV5ym/rasf6Yij46OztHTxabjv9CxY8esfv36WeXLl7fc3d2tevXq5To1f36nvT//533+q3///nbd559/brVq1cry9va2vL29rVq1alnR0dHWzp077ZqL/dxyO2b79u2zIiMjLS8vL6tChQrWiBEjrM8//9ySZP344492XVpamvXAAw9Yfn5+liR7Pdk/9wuns9+/f7/Tz2vfvn3Www8/bFWtWtXy9PS0ypYta7Vt29Zavnx5no7P/PnzrUaNGlkeHh5W2bJlrd69e1tHjhxxqimMae9z+3ldeF5mf3b16tXWwIEDrTJlylilSpWyevfubZ04ccLps5mZmdbIkSOt8uXLWyVLlrQiIiKsPXv25Hquvf3229Ytt9xiubq65msK/Nz2JTMz0xo/frxVsWJFy8vLy2rTpo21devWHNt96aWXrGbNmll+fn6Wl5eXVatWLWvChAlO0/kDKB4cllVEn6IGAKCYmTp1qoYNG6YjR47opptuMt1OkZP9RdXr169XkyZNTLcDAIWCZ8gAADDgzJkzTu///vtvvfnmm6pevTphDACKEZ4hAwDAgK5du+rmm29Ww4YNlZKSog8//FA7duzQRx99ZLq1Yi8tLU1paWmXrKlQocJFp+oHgPwgkAEAYEBERITeeecdffTRR8rMzFRoaKg++eQT9ejRw3Rrxd6rr76q8ePHX7Jm//79TtPsA0BB8QwZAADAefbt26d9+/ZdsqZVq1aXnGkVAPKKQAYAAAAAhjCpBwAAAAAYwjNkhSQrK0tHjx5V6dKlnb7QEwAAAEDxYlmWTp06paCgILm4XPoaGIGskBw9elTBwcGm2wAAAABQRBw+fFiVKlW6ZA2BrJCULl1a0j8H3cfHx3A3AAAAAExJTU1VcHCwnREuhUBWSLJvU/Tx8SGQAQAAAMjTo0xM6gEAAAAAhhDIAAAAAMAQAhkAAAAAGEIgAwAAAABDCGQAAAAAYAiBDAAAAAAMIZABAAAAgCEEMgAAAAAwhEAGAAAAAIYQyAAAAADAEAIZAAAAABhCIAMAAAAAQwhkAAAAAGAIgQwAAAAADDEayCZOnKimTZuqdOnS8vf3V5cuXbRz506nmjZt2sjhcDi9Bg0a5FRz6NAhRUZGqmTJkvL399dTTz2lc+fOOdWsWrVKt956qzw8PFStWjXFxMTk6OeNN95Q5cqV5enpqebNm+vnn38u9H0GAAAAgGxGA9nq1asVHR2tH3/8UXFxcTp79qzat2+v06dPO9U98sgjSkhIsF+TJk2yl2VmZioyMlIZGRn64Ycf9P777ysmJkZjxoyxa/bv36/IyEi1bdtWmzdv1tChQzVgwAAtXbrUrpk/f76GDx+usWPH6pdfflGDBg0UERGhpKSkq38gAAAAABRLDsuyLNNNZDt+/Lj8/f21evVqtW7dWtI/V8gaNmyoqVOn5vqZJUuW6O6779bRo0cVEBAgSZo9e7ZGjhyp48ePy93dXSNHjtQ333yjrVu32p/r2bOnkpOTFRsbK0lq3ry5mjZtqhkzZkiSsrKyFBwcrMcff1zPPPNMju2mp6crPT3dfp+amqrg4GClpKTIx8enUI4HAAAAgOtPamqqfH1985QNitQzZCkpKZKksmXLOo1/9NFHKl++vOrWratRo0bpr7/+spetW7dO9erVs8OYJEVERCg1NVXbtm2za8LDw53WGRERoXXr1kmSMjIytHHjRqcaFxcXhYeH2zUXmjhxonx9fe1XcHDwFew5AAAAgOLIzXQD2bKysjR06FC1bNlSdevWtccfeOABhYSEKCgoSFu2bNHIkSO1c+dOffHFF5KkxMREpzAmyX6fmJh4yZrU1FSdOXNGf/75pzIzM3Ot2bFjR679jho1SsOHD7ffZ18hAwAAAIC8KjKBLDo6Wlu3btX333/vND5w4ED7z/Xq1VPFihV11113ae/evapateq1btPm4eEhDw8PY9sHABRdnTub7uB/vv7adAcAgEspErcsDh48WIsXL9bKlStVqVKlS9Y2b95ckrRnzx5JUmBgoI4dO+ZUk/0+MDDwkjU+Pj7y8vJS+fLl5erqmmtN9joAAAAAoLAZDWSWZWnw4MFauHChVqxYoSpVqlz2M5s3b5YkVaxYUZIUFham3377zWk2xLi4OPn4+Cg0NNSuiY+Pd1pPXFycwsLCJEnu7u5q3LixU01WVpbi4+PtGgAAAAAobEZvWYyOjta8efP05ZdfqnTp0vYzX76+vvLy8tLevXs1b948derUSeXKldOWLVs0bNgwtW7dWvXr15cktW/fXqGhoXrwwQc1adIkJSYmavTo0YqOjrZvKRw0aJBmzJihp59+Wg8//LBWrFihTz/9VN98843dy/DhwxUVFaUmTZqoWbNmmjp1qk6fPq1+/fpd+wMDAAAAoFgwOu29w+HIdXzOnDnq27evDh8+rD59+mjr1q06ffq0goODdd9992n06NFO00cePHhQjz76qFatWiVvb29FRUXpP//5j9zc/pc3V61apWHDhun3339XpUqV9Pzzz6tv375O250xY4ZeeeUVJSYmqmHDhpo+fbp9i+Tl5GdqSwDAjY1nyACgeMtPNihS30N2PSOQAQCyEcgAoHi7br+HDAAAAACKEwIZAAAAABhCIAMAAAAAQwhkAAAAAGAIgQwAAAAADCGQAQAAAIAhBDIAAAAAMIRABgAAAACGEMgAAAAAwBACGQAAAAAYQiADAAAAAEMIZAAAAABgCIEMAAAAAAwhkAEAAACAIQQyAAAAADCEQAYAAAAAhhDIAAAAAMAQAhkAAAAAGEIgAwAAAABDCGQAAAAAYAiBDAAAAAAMIZABAAAAgCEEMgAAAAAwhEAGAAAAAIYQyAAAAADAEAIZAAAAABhCIAMAAAAAQwhkAAAAAGAIgQwAAAAADCGQAQAAAIAhBDIAAAAAMIRABgAAAACGEMgAAAAAwBACGQAAAAAYQiADAAAAAEMIZAAAAABgCIEMAAAAAAwhkAEAAACAIQQyAAAAADCEQAYAAAAAhhDIAAAAAMAQAhkAAAAAGEIgAwAAAABDCGQAAAAAYAiBDAAAAAAMIZABAAAAgCEEMgAAAAAwhEAGAAAAAIYQyAAAAADAEAIZAAAAABhCIAMAAAAAQwhkAAAAAGAIgQwAAAAADCGQAQAAAIAhBDIAAAAAMIRABgAAAACGEMgAAAAAwBACGQAAAAAYQiADAAAAAEMIZAAAAABgCIEMAAAAAAwhkAEAAACAIQQyAAAAADCEQAYAAAAAhhDIAAAAAMAQAhkAAAAAGEIgAwAAAABDCGQAAAAAYAiBDAAAAAAMIZABAAAAgCEEMgAAAAAwhEAGAAAAAIYQyAAAAADAEAIZAAAAABhCIAMAAAAAQwhkAAAAAGAIgQwAAAAADDEayCZOnKimTZuqdOnS8vf3V5cuXbRz506nmr///lvR0dEqV66cSpUqpW7duunYsWNONYcOHVJkZKRKliwpf39/PfXUUzp37pxTzapVq3TrrbfKw8ND1apVU0xMTI5+3njjDVWuXFmenp5q3ry5fv7550LfZwAAAADIZjSQrV69WtHR0frxxx8VFxens2fPqn379jp9+rRdM2zYMH399ddasGCBVq9eraNHj6pr16728szMTEVGRiojI0M//PCD3n//fcXExGjMmDF2zf79+xUZGam2bdtq8+bNGjp0qAYMGKClS5faNfPnz9fw4cM1duxY/fLLL2rQoIEiIiKUlJR0bQ4GAAAAgGLHYVmWZbqJbMePH5e/v79Wr16t1q1bKyUlRRUqVNC8efN0//33S5J27Nih2rVra926dWrRooWWLFmiu+++W0ePHlVAQIAkafbs2Ro5cqSOHz8ud3d3jRw5Ut988422bt1qb6tnz55KTk5WbGysJKl58+Zq2rSpZsyYIUnKyspScHCwHn/8cT3zzDOX7T01NVW+vr5KSUmRj49PYR8aAMB1pHNn0x38z9dfm+4AAIqf/GSDIvUMWUpKiiSpbNmykqSNGzfq7NmzCg8Pt2tq1aqlm2++WevWrZMkrVu3TvXq1bPDmCRFREQoNTVV27Zts2vOX0d2TfY6MjIytHHjRqcaFxcXhYeH2zUXSk9PV2pqqtMLAAAAAPKjyASyrKwsDR06VC1btlTdunUlSYmJiXJ3d5efn59TbUBAgBITE+2a88NY9vLsZZeqSU1N1ZkzZ/Tf//5XmZmZudZkr+NCEydOlK+vr/0KDg4u2I4DAAAAKLaKTCCLjo7W1q1b9cknn5huJU9GjRqllJQU+3X48GHTLQEAAAC4zriZbkCSBg8erMWLF2vNmjWqVKmSPR4YGKiMjAwlJyc7XSU7duyYAgMD7ZoLZ0PMnoXx/JoLZ2Y8duyYfHx85OXlJVdXV7m6uuZak72OC3l4eMjDw6NgOwwAAAAAMnyFzLIsDR48WAsXLtSKFStUpUoVp+WNGzdWiRIlFB8fb4/t3LlThw4dUlhYmCQpLCxMv/32m9NsiHFxcfLx8VFoaKhdc/46smuy1+Hu7q7GjRs71WRlZSk+Pt6uAQAAAIDCZvQKWXR0tObNm6cvv/xSpUuXtp/X8vX1lZeXl3x9fdW/f38NHz5cZcuWlY+Pjx5//HGFhYWpRYsWkqT27dsrNDRUDz74oCZNmqTExESNHj1a0dHR9hWsQYMGacaMGXr66af18MMPa8WKFfr000/1zTff2L0MHz5cUVFRatKkiZo1a6apU6fq9OnT6tev37U/MAAAAACKBaOBbNasWZKkNm3aOI3PmTNHffv2lSS99tprcnFxUbdu3ZSenq6IiAjNnDnTrnV1ddXixYv16KOPKiwsTN7e3oqKitILL7xg11SpUkXffPONhg0bpmnTpqlSpUp65513FBERYdf06NFDx48f15gxY5SYmKiGDRsqNjY2x0QfAAAAAFBYitT3kF3P+B4yAEA2vocMAIq36/Z7yAAAAACgOCGQAQAAAIAhBDIAAAAAMIRABgAAAACGEMgAAAAAwBACGQAAAAAYQiADAAAAAEMIZAAAAABgCIEMAAAAAAwhkAEAAACAIQQyAAAAADCEQAYAAAAAhhDIAAAAAMAQAhkAAAAAGEIgAwAAAABDCGQAAAAAYAiBDAAAAAAMIZABAAAAgCEEMgAAAAAwhEAGAAAAAIYQyAAAAADAEAIZAAAAABhCIAMAAAAAQwhkAAAAAGAIgQwAAAAADCGQAQAAAIAhBDIAAAAAMIRABgAAAACGEMgAAAAAwBACGQAAAAAYQiADAAAAAEMIZAAAAABgCIEMAAAAAAwhkAEAAACAIQQyAAAAADCEQAYAAAAAhhDIAAAAAMAQAhkAAAAAGEIgAwAAAABDCGQAAAAAYAiBDAAAAAAMIZABAAAAgCEEMgAAAAAwhEAGAAAAAIYQyAAAAADAEAIZAAAAABhCIAMAAAAAQwhkAAAAAGAIgQwAAAAADCGQAQAAAIAhBDIAAAAAMIRABgAAAACGEMgAAAAAwBACGQAAAAAYQiADAAAAAEMIZAAAAABgCIEMAAAAAAwhkAEAAACAIQQyAAAAADCEQAYAAAAAhhDIAAAAAMAQAhkAAAAAGEIgAwAAAABDCGQAAAAAYAiBDAAAAAAMIZABAAAAgCEEMgAAAAAwhEAGAAAAAIYQyAAAAADAEAIZAAAAABhCIAMAAAAAQwhkAAAAAGAIgQwAAAAADCGQAQAAAIAhBDIAAAAAMIRABgAAAACGEMgAAAAAwBCjgWzNmjXq3LmzgoKC5HA4tGjRIqflffv2lcPhcHp16NDBqebkyZPq3bu3fHx85Ofnp/79+ystLc2pZsuWLbr99tvl6emp4OBgTZo0KUcvCxYsUK1ateTp6al69erp22+/LfT9BQAAAIDzGQ1kp0+fVoMGDfTGG29ctKZDhw5KSEiwXx9//LHT8t69e2vbtm2Ki4vT4sWLtWbNGg0cONBenpqaqvbt2yskJEQbN27UK6+8onHjxumtt96ya3744Qf16tVL/fv316ZNm9SlSxd16dJFW7duLfydBgAAAID/z2FZlmW6CUlyOBxauHChunTpYo/17dtXycnJOa6cZdu+fbtCQ0O1fv16NWnSRJIUGxurTp066ciRIwoKCtKsWbP03HPPKTExUe7u7pKkZ555RosWLdKOHTskST169NDp06e1ePFie90tWrRQw4YNNXv27Dz1n5qaKl9fX6WkpMjHx6cARwAAcKPo3Nl0B//z9demOwCA4ic/2aDIP0O2atUq+fv7q2bNmnr00Ud14sQJe9m6devk5+dnhzFJCg8Pl4uLi3766Se7pnXr1nYYk6SIiAjt3LlTf/75p10THh7utN2IiAitW7fuon2lp6crNTXV6QUAAAAA+VGkA1mHDh00d+5cxcfH6+WXX9bq1avVsWNHZWZmSpISExPl7+/v9Bk3NzeVLVtWiYmJdk1AQIBTTfb7y9VkL8/NxIkT5evra7+Cg4OvbGcBAAAAFDtuBfnQvn37dMsttxR2Lzn07NnT/nO9evVUv359Va1aVatWrdJdd9111bd/KaNGjdLw4cPt96mpqYQyAAAAAPlSoCtk1apVU9u2bfXhhx/q77//LuyeLuqWW25R+fLltWfPHklSYGCgkpKSnGrOnTunkydPKjAw0K45duyYU032+8vVZC/PjYeHh3x8fJxeAAAAAJAfBQpkv/zyi+rXr6/hw4crMDBQ//rXv/Tzzz8Xdm85HDlyRCdOnFDFihUlSWFhYUpOTtbGjRvtmhUrVigrK0vNmze3a9asWaOzZ8/aNXFxcapZs6bKlClj18THxzttKy4uTmFhYVd7lwAAAAAUYwUKZA0bNtS0adN09OhRvffee0pISFCrVq1Ut25dTZkyRcePH8/TetLS0rR582Zt3rxZkrR//35t3rxZhw4dUlpamp566in9+OOPOnDggOLj43XvvfeqWrVqioiIkCTVrl1bHTp00COPPKKff/5Za9eu1eDBg9WzZ08FBQVJkh544AG5u7urf//+2rZtm+bPn69p06Y53W44ZMgQxcbGavLkydqxY4fGjRunDRs2aPDgwQU5PAAAAACQJ4Uy7X16erpmzpypUaNGKSMjQ+7u7urevbtefvll+2pWblatWqW2bdvmGI+KitKsWbPUpUsXbdq0ScnJyQoKClL79u314osvOk3AcfLkSQ0ePFhff/21XFxc1K1bN02fPl2lSpWya7Zs2aLo6GitX79e5cuX1+OPP66RI0c6bXPBggUaPXq0Dhw4oOrVq2vSpEnq1KlTno8B094DALIx7T0AFG/5yQZXFMg2bNig9957T5988om8vb0VFRWl/v3768iRIxo/frxSU1Ovya2MRQGBDACQjUAGAMVbfrJBgWZZnDJliubMmaOdO3eqU6dOmjt3rjp16iQXl3/ugKxSpYpiYmJUuXLlgqweAAAAAIqFAgWyWbNm6eGHH1bfvn0vekuiv7+/3n333StqDgAAAABuZAUKZLt3775sjbu7u6KiogqyegAAAAAoFgo0y+KcOXO0YMGCHOMLFizQ+++/f8VNAQAAAEBxUKBANnHiRJUvXz7HuL+/v/79739fcVMAAAAAUBwUKJAdOnRIVapUyTEeEhKiQ4cOXXFTAAAAAFAcFCiQ+fv7a8uWLTnGf/31V5UrV+6KmwIAAACA4qBAgaxXr1564okntHLlSmVmZiozM1MrVqzQkCFD1LNnz8LuEQAAAABuSAWaZfHFF1/UgQMHdNddd8nN7Z9VZGVl6aGHHuIZMgAAAADIowIFMnd3d82fP18vvviifv31V3l5ealevXoKCQkp7P4AAAAA4IZVoECWrUaNGqpRo0Zh9QIAAAAAxUqBAllmZqZiYmIUHx+vpKQkZWVlOS1fsWJFoTQHAAAAADeyAgWyIUOGKCYmRpGRkapbt64cDkdh9wUAAAAAN7wCBbJPPvlEn376qTp16lTY/QAAAABAsVGgae/d3d1VrVq1wu4FAAAAAIqVAgWyESNGaNq0abIsq7D7AQAAAIBio0C3LH7//fdauXKllixZojp16qhEiRJOy7/44otCaQ4AAAAAbmQFCmR+fn667777CrsXAAAAAChWChTI5syZU9h9AAAAAECxU6BnyCTp3LlzWr58ud58802dOnVKknT06FGlpaUVWnMAAAAAcCMr0BWygwcPqkOHDjp06JDS09PVrl07lS5dWi+//LLS09M1e/bswu4TAAAAAG44BbpCNmTIEDVp0kR//vmnvLy87PH77rtP8fHxhdYcAAAAANzICnSF7LvvvtMPP/wgd3d3p/HKlSvrjz/+KJTGAAAAAOBGV6ArZFlZWcrMzMwxfuTIEZUuXfqKmwIAAACA4qBAgax9+/aaOnWq/d7hcCgtLU1jx45Vp06dCqs3AAAAALihFeiWxcmTJysiIkKhoaH6+++/9cADD2j37t0qX768Pv7448LuEQAAAABuSAUKZJUqVdKvv/6qTz75RFu2bFFaWpr69++v3r17O03yAQAAAAC4uAIFMklyc3NTnz59CrMXAAAAAChWChTI5s6de8nlDz30UIGaAQAAAIDipECBbMiQIU7vz549q7/++kvu7u4qWbIkgQwAAAAA8qBAsyz++eefTq+0tDTt3LlTrVq1YlIPAAAAAMijAgWy3FSvXl3/+c9/clw9AwAAAADkrtACmfTPRB9Hjx4tzFUCAAAAwA2rQM+QffXVV07vLctSQkKCZsyYoZYtWxZKYwAAAABwoytQIOvSpYvTe4fDoQoVKujOO+/U5MmTC6MvAAAAALjhFSiQZWVlFXYfAAAAAFDsFOozZAAAAACAvCvQFbLhw4fnuXbKlCkF2QQAAAAA3PAKFMg2bdqkTZs26ezZs6pZs6YkadeuXXJ1ddWtt95q1zkcjsLpEgAAAABuQAUKZJ07d1bp0qX1/vvvq0yZMpL++bLofv366fbbb9eIESMKtUkAAAAAuBE5LMuy8vuhm266ScuWLVOdOnWcxrdu3ar27dsXy+8iS01Nla+vr1JSUuTj42O6HQCAQZ07m+7gf77+2nQHAFD85CcbFGhSj9TUVB0/fjzH+PHjx3Xq1KmCrBIAAAAAip0CBbL77rtP/fr10xdffKEjR47oyJEj+vzzz9W/f3917dq1sHsEAAAAgBtSgZ4hmz17tp588kk98MADOnv27D8rcnNT//799corrxRqgwAAAABwoyrQM2TZTp8+rb1790qSqlatKm9v70Jr7HrDM2QAgGw8QwYAxdtVf4YsW0JCghISElS9enV5e3vrCrIdAAAAABQ7BQpkJ06c0F133aUaNWqoU6dOSkhIkCT179+fKe8BAAAAII8KFMiGDRumEiVK6NChQypZsqQ93qNHD8XGxhZacwAAAABwIyvQpB7Lli3T0qVLValSJafx6tWr6+DBg4XSGAAAAADc6Ap0hez06dNOV8aynTx5Uh4eHlfcFAAAAAAUBwUKZLfffrvmzp1rv3c4HMrKytKkSZPUtm3bQmsOAAAAAG5kBbplcdKkSbrrrru0YcMGZWRk6Omnn9a2bdt08uRJrV27trB7BAAAAIAbUoGukNWtW1e7du1Sq1atdO+99+r06dPq2rWrNm3apKpVqxZ2jwAAAABwQ8r3FbKzZ8+qQ4cOmj17tp577rmr0RMAAAAAFAv5vkJWokQJbdmy5Wr0AgAAAADFSoFuWezTp4/efffdwu4FAAAAAIqVAk3qce7cOb333ntavny5GjduLG9vb6flU6ZMKZTmAAAAAOBGlq9Atm/fPlWuXFlbt27VrbfeKknatWuXU43D4Si87gAAAADgBpavQFa9enUlJCRo5cqVkqQePXpo+vTpCggIuCrNAQAAAMCNLF/PkFmW5fR+yZIlOn36dKE2BAAAAADFRYEm9ch2YUADAAAAAORdvgKZw+HI8YwYz4wBAAAAQMHk6xkyy7LUt29feXh4SJL+/vtvDRo0KMcsi1988UXhdQgAAAAAN6h8BbKoqCin93369CnUZgAAAACgOMlXIJszZ87V6gMAAAAAip0rmtQDAAAAAFBwBDIAAAAAMIRABgAAAACGEMgAAAAAwBACGQAAAAAYQiADAAAAAEMIZAAAAABgCIEMAAAAAAwhkAEAAACAIQQyAAAAADCEQAYAAAAAhhDIAAAAAMAQo4FszZo16ty5s4KCguRwOLRo0SKn5ZZlacyYMapYsaK8vLwUHh6u3bt3O9WcPHlSvXv3lo+Pj/z8/NS/f3+lpaU51WzZskW33367PD09FRwcrEmTJuXoZcGCBapVq5Y8PT1Vr149ffvtt4W+vwAAAABwPqOB7PTp02rQoIHeeOONXJdPmjRJ06dP1+zZs/XTTz/J29tbERER+vvvv+2a3r17a9u2bYqLi9PixYu1Zs0aDRw40F6empqq9u3bKyQkRBs3btQrr7yicePG6a233rJrfvjhB/Xq1Uv9+/fXpk2b1KVLF3Xp0kVbt269ejsPAAAAoNhzWJZlmW5CkhwOhxYuXKguXbpI+ufqWFBQkEaMGKEnn3xSkpSSkqKAgADFxMSoZ8+e2r59u0JDQ7V+/Xo1adJEkhQbG6tOnTrpyJEjCgoK0qxZs/Tcc88pMTFR7u7ukqRnnnlGixYt0o4dOyRJPXr00OnTp7V48WK7nxYtWqhhw4aaPXt2nvpPTU2Vr6+vUlJS5OPjU1iHBQBwHerc2XQH//P116Y7AIDiJz/ZoMg+Q7Z//34lJiYqPDzcHvP19VXz5s21bt06SdK6devk5+dnhzFJCg8Pl4uLi3766Se7pnXr1nYYk6SIiAjt3LlTf/75p11z/naya7K3k5v09HSlpqY6vQAAAAAgP4psIEtMTJQkBQQEOI0HBATYyxITE+Xv7++03M3NTWXLlnWqyW0d52/jYjXZy3MzceJE+fr62q/g4OD87iIAAACAYq7IBrKibtSoUUpJSbFfhw8fNt0SAAAAgOtMkQ1kgYGBkqRjx445jR87dsxeFhgYqKSkJKfl586d08mTJ51qclvH+du4WE328tx4eHjIx8fH6QUAAAAA+VFkA1mVKlUUGBio+Ph4eyw1NVU//fSTwsLCJElhYWFKTk7Wxo0b7ZoVK1YoKytLzZs3t2vWrFmjs2fP2jVxcXGqWbOmypQpY9ecv53smuztAAAAAMDVYDSQpaWlafPmzdq8ebOkfyby2Lx5sw4dOiSHw6GhQ4fqpZde0ldffaXffvtNDz30kIKCguyZGGvXrq0OHTrokUce0c8//6y1a9dq8ODB6tmzp4KCgiRJDzzwgNzd3dW/f39t27ZN8+fP17Rp0zR8+HC7jyFDhig2NlaTJ0/Wjh07NG7cOG3YsEGDBw++1ocEAAAAQDHiZnLjGzZsUNu2be332SEpKipKMTExevrpp3X69GkNHDhQycnJatWqlWJjY+Xp6Wl/5qOPPtLgwYN11113ycXFRd26ddP06dPt5b6+vlq2bJmio6PVuHFjlS9fXmPGjHH6rrLbbrtN8+bN0+jRo/Xss8+qevXqWrRokerWrXsNjgIAAACA4qrIfA/Z9Y7vIQMAZON7yACgeLshvocMAAAAAG50BDIAAAAAMIRABgAAAACGEMgAAAAAwBACGQAAAAAYQiADAAAAAEMIZAAAAABgCIEMAAAAAAwhkAEAAACAIQQyAAAAADCEQAYAAAAAhhDIAAAAAMAQAhkAAAAAGEIgAwAAAABDCGQAAAAAYAiBDAAAAAAMIZABAAAAgCEEMgAAAAAwhEAGAAAAAIYQyAAAAADAEAIZAAAAABhCIAMAAAAAQwhkAAAAAGAIgQwAAAAADCGQAQAAAIAhBDIAAAAAMIRABgAAAACGEMgAAAAAwBACGQAAAAAYQiADAAAAAEMIZAAAAABgCIEMAAAAAAwhkAEAAACAIQQyAAAAADCEQAYAAAAAhhDIAAAAAMAQAhkAAAAAGEIgAwAAAABDCGQAAAAAYAiBDAAAAAAMIZABAAAAgCEEMgAAAAAwhEAGAAAAAIYQyAAAAADAEAIZAAAAABhCIAMAAAAAQwhkAAAAAGAIgQwAAAAADCGQAQAAAIAhBDIAAAAAMIRABgAAAACGEMgAAAAAwBACGQAAAAAYQiADAAAAAEMIZAAAAABgCIEMAAAAAAwhkAEAAACAIQQyAAAAADCEQAYAAAAAhhDIAAAAAMAQAhkAAAAAGEIgAwAAAABDCGQAAAAAYAiBDAAAAAAMIZABAAAAgCEEMgAAAAAwhEAGAAAAAIYQyAAAAADAEAIZAAAAABhCIAMAAAAAQwhkAAAAAGAIgQwAAAAADCGQAQAAAIAhBDIAAAAAMIRABgAAAACGEMgAAAAAwBACGQAAAAAYQiADAAAAAEOKdCAbN26cHA6H06tWrVr28r///lvR0dEqV66cSpUqpW7duunYsWNO6zh06JAiIyNVsmRJ+fv766mnntK5c+ecalatWqVbb71VHh4eqlatmmJiYq7F7gEAAAAo5op0IJOkOnXqKCEhwX59//339rJhw4bp66+/1oIFC7R69WodPXpUXbt2tZdnZmYqMjJSGRkZ+uGHH/T+++8rJiZGY8aMsWv279+vyMhItW3bVps3b9bQoUM1YMAALV269JruJwAAAIDix810A5fj5uamwMDAHOMpKSl69913NW/ePN15552SpDlz5qh27dr68ccf1aJFCy1btky///67li9froCAADVs2FAvvviiRo4cqXHjxsnd3V2zZ89WlSpVNHnyZElS7dq19f333+u1115TRETERftKT09Xenq6/T41NbWQ9xwAAADAja7IXyHbvXu3goKCdMstt6h37946dOiQJGnjxo06e/aswsPD7dpatWrp5ptv1rp16yRJ69atU7169RQQEGDXREREKDU1Vdu2bbNrzl9Hdk32Oi5m4sSJ8vX1tV/BwcGFsr8AAAAAio8iHciaN2+umJgYxcbGatasWdq/f79uv/12nTp1SomJiXJ3d5efn5/TZwICApSYmChJSkxMdApj2cuzl12qJjU1VWfOnLlob6NGjVJKSor9Onz48JXuLgAAAIBipkjfstixY0f7z/Xr11fz5s0VEhKiTz/9VF5eXgY7kzw8POTh4WG0BwAAAADXtyJ9hexCfn5+qlGjhvbs2aPAwEBlZGQoOTnZqebYsWP2M2eBgYE5Zl3Mfn+5Gh8fH+OhDwAAAMCN7boKZGlpadq7d68qVqyoxo0bq0SJEoqPj7eX79y5U4cOHVJYWJgkKSwsTL/99puSkpLsmri4OPn4+Cg0NNSuOX8d2TXZ6wAAAACAq6VIB7Inn3xSq1ev1oEDB/TDDz/ovvvuk6urq3r16iVfX1/1799fw4cP18qVK7Vx40b169dPYWFhatGihSSpffv2Cg0N1YMPPqhff/1VS5cu1ejRoxUdHW3fbjho0CDt27dPTz/9tHbs2KGZM2fq008/1bBhw0zuOgAAAIBioEg/Q3bkyBH16tVLJ06cUIUKFdSqVSv9+OOPqlChgiTptddek4uLi7p166b09HRFRERo5syZ9uddXV21ePFiPfroowoLC5O3t7eioqL0wgsv2DVVqlTRN998o2HDhmnatGmqVKmS3nnnnUtOeQ8AAAAAhcFhWZZluokbQWpqqnx9fZWSkiIfHx/T7QAADOrc2XQH//P116Y7AIDiJz/ZoEjfsggAAAAANzICGQAAAAAYQiADAAAAAEMIZAAAAABgCIEMAAAAAAwhkAEAAACAIQQyAAAAADCEQAYAAAAAhhDIAAAAAMAQAhkAAAAAGEIgAwAAAABDCGQAAAAAYAiBDAAAAAAMIZABAAAAgCEEMgAAAAAwhEAGAAAAAIYQyAAAAADAEAIZAAAAABhCIAMAAAAAQwhkAAAAAGAIgQwAAAAADCGQAQAAAIAhBDIAAAAAMIRABgAAAACGEMgAAAAAwBACGQAAAAAYQiADAAAAAEMIZAAAAABgCIEMAAAAAAwhkAEAAACAIQQyAAAAADCEQAYAAAAAhhDIAAAAAMAQAhkAAAAAGEIgAwAAAABDCGQAAAAAYAiBDAAAAAAMIZABAAAAgCEEMgAAAAAwhEAGAAAAAIYQyAAAAADAEAIZAAAAABhCIAMAAAAAQwhkAAAAAGAIgQwAAAAADCGQAQAAAIAhBDIAAAAAMIRABgAAAACGEMgAAAAAwBACGQAAAAAYQiADAAAAAEMIZAAAAABgCIEMAAAAAAwhkAEAAACAIQQyAAAAADCEQAYAAAAAhhDIAAAAAMAQAhkAAAAAGEIgAwAAAABDCGQAAAAAYAiBDAAAAAAMIZABAAAAgCEEMgAAAAAwhEAGAAAAAIYQyAAAAADAEAIZAAAAABhCIAMAAAAAQwhkAAAAAGAIgQwAAAAADCGQAQAAAIAhBDIAAAAAMIRABgAAAACGEMgAAAAAwBACGQAAAAAYQiADAAAAAEMIZAAAAABgCIEMAAAAAAwhkF3gjTfeUOXKleXp6anmzZvr559/Nt0SAAAAgBsUgew88+fP1/DhwzV27Fj98ssvatCggSIiIpSUlGS6NQAAAAA3IALZeaZMmaJHHnlE/fr1U2hoqGbPnq2SJUvqvffeM90aAAAAgBuQm+kGioqMjAxt3LhRo0aNssdcXFwUHh6udevW5ahPT09Xenq6/T4lJUWSlJqaevWbBQAUaWfPmu7gf/i1BADXXnYmsCzrsrUEsv/vv//9rzIzMxUQEOA0HhAQoB07duSonzhxosaPH59jPDg4+Kr1CABAfvn6mu4AAIqvU6dOyfcy/xATyApo1KhRGj58uP0+KytLJ0+eVLly5eRwOAx2hktJTU1VcHCwDh8+LB8fH9Pt4DrAOYP84pxBfnHOID84X64PlmXp1KlTCgoKumwtgez/K1++vFxdXXXs2DGn8WPHjikwMDBHvYeHhzw8PJzG/Pz8rmaLKEQ+Pj78I4Z84ZxBfnHOIL84Z5AfnC9F3+WujGVjUo//z93dXY0bN1Z8fLw9lpWVpfj4eIWFhRnsDAAAAMCNiitk5xk+fLiioqLUpEkTNWvWTFOnTtXp06fVr18/060BAAAAuAERyM7To0cPHT9+XGPGjFFiYqIaNmyo2NjYHBN94Prl4eGhsWPH5rjdFLgYzhnkF+cM8otzBvnB+XLjcVh5mYsRAAAAAFDoeIYMAAAAAAwhkAEAAACAIQQyAAAAADCEQAYAAAAAhhDIUCRNnDhRTZs2VenSpeXv768uXbpo586dTjV///23oqOjVa5cOZUqVUrdunXL8cXe2U6cOKFKlSrJ4XAoOTnZHu/bt68cDkeOV506dS7Zn2VZevXVV1WjRg15eHjopptu0oQJE654v1FwRf2cWbp0qVq0aKHSpUurQoUK6tatmw4cOHClu40rcK3OGUn66KOP1KBBA5UsWVIVK1bUww8/rBMnTlyyv0OHDikyMlIlS5aUv7+/nnrqKZ07d+6K9hkFV5TPl19//VW9evVScHCwvLy8VLt2bU2bNu2K9xlXpiifM3ldL64RCyiCIiIirDlz5lhbt261Nm/ebHXq1Mm6+eabrbS0NLtm0KBBVnBwsBUfH29t2LDBatGihXXbbbflur57773X6tixoyXJ+vPPP+3x5ORkKyEhwX4dPnzYKlu2rDV27NhL9vf4449bNWvWtL788ktr37591oYNG6xly5YVxq6jgIryObNv3z7Lw8PDGjVqlLVnzx5r48aNVuvWra1GjRoV1u6jAK7VOfP9999bLi4u1rRp06x9+/ZZ3333nVWnTh3rvvvuu2hv586ds+rWrWuFh4dbmzZtsr799lurfPny1qhRowpt/5E/Rfl8effdd60nnnjCWrVqlbV3717rgw8+sLy8vKzXX3+90PYf+VeUz5m8rBfXDoEM14WkpCRLkrV69WrLsv75j+ISJUpYCxYssGu2b99uSbLWrVvn9NmZM2dad9xxhxUfH3/Zf2wWLlxoORwO68CBAxet+f333y03Nzdrx44dV7ZTuKqK0jmzYMECy83NzcrMzLTHvvrqK8vhcFgZGRkF3EMUtqt1zrzyyivWLbfc4lQ/ffp066abbrpoL99++63l4uJiJSYm2mOzZs2yfHx8rPT09CvZTRSSonS+5Oaxxx6z2rZtm8+9wtVUFM+Z/Py+w9XDLYu4LqSkpEiSypYtK0nauHGjzp49q/DwcLumVq1auvnmm7Vu3Tp77Pfff9cLL7yguXPnysXl8qf7u+++q/DwcIWEhFy05uuvv9Ytt9yixYsXq0qVKqpcubIGDBigkydPFnT3cBUUpXOmcePGcnFx0Zw5c5SZmamUlBR98MEHCg8PV4kSJQq6iyhkV+ucCQsL0+HDh/Xtt9/KsiwdO3ZMn332mTp16nTRXtatW6d69eopICDAHouIiFBqaqq2bdt2xfuKK1eUzpeL9ZfdG4qGonbO5Pf3Ha4ejj6KvKysLA0dOlQtW7ZU3bp1JUmJiYlyd3eXn5+fU21AQIASExMlSenp6erVq5deeeUV3XzzzZfdztGjR7VkyRINGDDgknX79u3TwYMHtWDBAs2dO1cxMTHauHGj7r///oLtIApdUTtnqlSpomXLlunZZ5+Vh4eH/Pz8dOTIEX366acF20EUuqt5zrRs2VIfffSRevToIXd3dwUGBsrX11dvvPHGRftJTEx0CmPZ281eBrOK2vlyoR9++EHz58/XwIEDC7aDKHRF7ZzJ7+87XF0EMhR50dHR2rp1qz755JN8fW7UqFGqXbu2+vTpk6f6999/X35+furSpcsl67KyspSenq65c+fq9ttvV5s2bfTuu+9q5cqVOR7WhRlF7ZxJTEzUI488oqioKK1fv16rV6+Wu7u77r//flmWla8ecXVczXPm999/15AhQzRmzBht3LhRsbGxOnDggAYNGnSlbcOQony+bN26Vffee6/Gjh2r9u3b56s/XD1F7ZzJ7+87XGVm75gELi06OtqqVKmStW/fPqfxi93rfPPNN1tTpkyxLMuyGjRoYLm4uFiurq6Wq6ur5eLiYkmyXF1drTFjxjh9Lisry6pWrZo1dOjQy/Y0ZswYy83NzWnsr7/+siQxsUcRUBTPmdGjR1tNmjRxGjt8+HCuzwng2rva50yfPn2s+++/32kd3333nSXJOnr0aK49Pf/881aDBg2cxvbt22dJsn755Zcr2FtcqaJ4vmTbtm2b5e/vbz377LNXuJcoTEXxnMnP7ztcfW7XPAECeWBZlh5//HEtXLhQq1atUpUqVZyWN27cWCVKlFB8fLy6desmSdq5c6cOHTqksLAwSdLnn3+uM2fO2J9Zv369Hn74YX333XeqWrWq0/pWr16tPXv2qH///pftrWXLljp37pz27t1rr2fXrl2SdMnniHB1FeVz5q+//spxf76rq6ukf664woxrdc789ddfcnNz/nWb/fO3LnKFNCwsTBMmTFBSUpL8/f0lSXFxcfLx8VFoaGgh7D3yqyifL5K0bds23XnnnYqKiuJrWIqIonzO5Of3Ha4Bc1kQuLhHH33U8vX1tVatWuU0xfhff/1l1wwaNMi6+eabrRUrVlgbNmywwsLCrLCwsIuuc+XKlRedQahPnz5W8+bNc/3c66+/bt155532+8zMTOvWW2+1Wrdubf3yyy/Whg0brObNm1vt2rUr+A7jihXlcyY+Pt5yOBzW+PHjrV27dlkbN260IiIirJCQEKf+cG1dq3Nmzpw5lpubmzVz5kxr79691vfff281adLEatasmV3zxRdfWDVr1rTfZ0973759e2vz5s1WbGysVaFCBaa9N6gony+//fabVaFCBatPnz5OvSUlJRXuQUC+FOVzJi/rxbVDIEORJCnX15w5c+yaM2fOWI899phVpkwZq2TJktZ9991nJSQkXHSdF/vHJjk52fLy8rLeeuutXD83duxYKyQkxGnsjz/+sLp27WqVKlXKCggIsPr27WudOHGioLuLQlDUz5mPP/7YatSokeXt7W1VqFDBuueee6zt27cXdHdRCK7lOTN9+nQrNDTU8vLysipWrGj17t3bOnLkiL18zpw51oX/H+mBAwesjh07Wl5eXlb58uWtESNGWGfPni2UfUf+FeXzZezYsbn2duG/Q7i2ivI5k9f14tpwWBZPlAMAAACACcyyCAAAAACGEMgAAAAAwBACGQAAAAAYQiADAAAAAEMIZAAAAABgCIEMAAAAAAwhkAEAAACAIQQyAAAAADCEQAYAKBb69u2rLl26FPp6ExMT1a5dO3l7e8vPz++abvtqqFy5sqZOnXrJGofDoUWLFl2TfgDgRkcgAwAUmqIQPA4cOCCHw6HNmzdfk+299tprSkhI0ObNm7Vr165ca6ZNm6aYmJhr0s/5YmJiLhoSL2b9+vUaOHDg1WkIAJCDm+kGAAC4nu3du1eNGzdW9erVL1rj6+t7DTu6MhUqVDDdAgAUK1whAwBcM1u3blXHjh1VqlQpBQQE6MEHH9R///tfe3mbNm30xBNP6Omnn1bZsmUVGBiocePGOa1jx44datWqlTw9PRUaGqrly5c73UJXpUoVSVKjRo3kcDjUpk0bp8+/+uqrqlixosqVK6fo6GidPXv2kj3PmjVLVatWlbu7u2rWrKkPPvjAXla5cmV9/vnnmjt3rhwOh/r27ZvrOi68cpiX/XQ4HJo1a5Y6duwoLy8v3XLLLfrss8/s5atWrZLD4VBycrI9tnnzZjkcDh04cECrVq1Sv379lJKSIofDIYfDkWMbubnwlsXdu3erdevW9vGOi4tzqs/IyNDgwYNVsWJFeXp6KiQkRBMnTrzsdgAA/yCQAQCuieTkZN15551q1KiRNmzYoNjYWB07dkzdu3d3qnv//ffl7e2tn376SZMmTdILL7xgh4DMzEx16dJFJUuW1E8//aS33npLzz33nNPnf/75Z0nS8uXLlZCQoC+++MJetnLlSu3du1crV67U+++/r5iYmEveSrhw4UINGTJEI0aM0NatW/Wvf/1L/fr108qVKyX9c3tfhw4d1L17dyUkJGjatGl5Ph6X2s9szz//vLp166Zff/1VvXv3Vs+ePbV9+/Y8rf+2227T1KlT5ePjo4SEBCUkJOjJJ5/Mc3+SlJWVpa5du8rd3V0//fSTZs+erZEjRzrVTJ8+XV999ZU+/fRT7dy5Ux999JEqV66cr+0AQHHGLYsAgGtixowZatSokf7973/bY++9956Cg4O1a9cu1ahRQ5JUv359jR07VpJUvXp1zZgxQ/Hx8WrXrp3i4uK0d+9erVq1SoGBgZKkCRMmqF27dvY6s2+5K1eunF2TrUyZMpoxY4ZcXV1Vq1YtRUZGKj4+Xo888kiuPb/66qvq27evHnvsMUnS8OHD9eOPP+rVV19V27ZtVaFCBXl4eMjLyyvHti7nUvuZ7f/+7/80YMAASdKLL76ouLg4vf7665o5c+Zl1+/u7i5fX185HI5895Zt+fLl2rFjh5YuXaqgoCBJ0r///W917NjRrjl06JCqV6+uVq1ayeFwKCQkpEDbAoDiiitkAIBr4tdff9XKlStVqlQp+1WrVi1J/zyHla1+/fpOn6tYsaKSkpIkSTt37lRwcLBTwGjWrFmee6hTp45cXV1zXXdutm/frpYtWzqNtWzZMs9XqS7lUvuZLSwsLMf7wth2Xm3fvl3BwcF2GMutp759+2rz5s2qWbOmnnjiCS1btuya9QcANwKukAEArom0tDR17txZL7/8co5lFStWtP9cokQJp2UOh0NZWVmF0sPVXPe17sXF5Z//T9WyLHvscs/DXQ233nqr9u/fryVLlmj58uXq3r27wsPDnZ53AwBcHFfIAADXxK233qpt27apcuXKqlatmtPL29s7T+uoWbOmDh8+rGPHjtlj69evd6pxd3eX9M/zZleqdu3aWrt2rdPY2rVrFRoaesXrzosff/wxx/vatWtL+t+tmQkJCfbyC6f6d3d3v6LjULt2bR0+fNhpGxf2JEk+Pj7q0aOH3n77bc2fP1+ff/65Tp48WeDtAkBxwhUyAEChSklJyREMsmc0fPvtt9WrVy97dsE9e/bok08+0TvvvON0K+HFtGvXTlWrVlVUVJQmTZqkU6dOafTo0ZL+ucIkSf7+/vLy8lJsbKwqVaokT0/PAk87/9RTT6l79+5q1KiRwsPD9fXXX+uLL77Q8uXLC7S+/FqwYIGaNGmiVq1a6aOPPtLPP/+sd999V5JUrVo1BQcHa9y4cZowYYJ27dqlyZMnO32+cuXKSktLU3x8vBo0aKCSJUuqZMmSed5+eHi4atSooaioKL3yyitKTU3NMYnKlClTVLFiRTVq1EguLi5asGCBAgMD8/39ZwBQXHGFDABQqFatWqVGjRo5vcaPH6+goCCtXbtWmZmZat++verVq6ehQ4fKz8/Pvv3uclxdXbVo0SKlpaWpadOmGjBggB0QPD09JUlubm6aPn263nzzTQUFBenee+8t8L506dJF06ZN06uvvqo6derozTff1Jw5c3JMpX+1jB8/Xp988onq16+vuXPn6uOPP7avzpUoUUIff/yxduzYofr16+vll1/WSy+95PT52267TYMGDVKPHj1UoUIFTZo0KV/bd3Fx0cKFC3XmzBk1a9ZMAwYM0IQJE5xqSpcurUmTJqlJkyZq2rSpDhw4oG+//TbPP1MAKO4c1vk3nwMAcJ1Zu3atWrVqpT179qhq1aqm2yk0DodDCxcudPr+MgDAjYdbFgEA15WFCxeqVKlSql69uvbs2aMhQ4aoZcuWN1QYAwAUHwQyAMB15dSpUxo5cqQOHTqk8uXLKzw8PMezU8jdd9995/QdYhdKS0u7ht0AACRuWQQAoNg4c+aM/vjjj4sur1at2jXsBgAgEcgAAAAAwBimQAIAAAAAQwhkAAAAAGAIgQwAAAAADCGQAQAAAIAhBDIAAAAAMIRABgAAAACGEMgAAAAAwJD/By76QuYlgEGtAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad649024-998b-405c-b217-5bcb21ceb56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91dbd52b-2f0e-48db-99ba-b9b2a560d422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87df72ae-24fc-45e9-91af-9d4e51cfb626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db5c1f97-a255-4d68-adb0-498b8f55040a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (1.2.0.dev0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (0.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: pyyaml in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (2.1.3)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (2.5.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.16.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2024.9.0)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2024.7.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9f5258e-5ed6-4a81-bffd-ce238fa73b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1221595-3f5c-4a0c-a215-e75f822571b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 22030336 || all params: 4562630656 || trainable%: 0.4828428523143645\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)\n",
    "\n",
    "# Apply the accelerator. You can comment this out to remove the accelerator.\n",
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62b92005-6029-4796-ae07-0db6ea5934ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): PeftModelForCausalLM(\n",
      "      (base_model): LoraModel(\n",
      "        (model): PeftModelForCausalLM(\n",
      "          (base_model): LoraModel(\n",
      "            (model): PeftModelForCausalLM(\n",
      "              (base_model): LoraModel(\n",
      "                (model): PeftModelForCausalLM(\n",
      "                  (base_model): LoraModel(\n",
      "                    (model): LlamaForCausalLM(\n",
      "                      (model): LlamaModel(\n",
      "                        (embed_tokens): Embedding(128256, 4096)\n",
      "                        (layers): ModuleList(\n",
      "                          (0-31): 32 x LlamaDecoderLayer(\n",
      "                            (self_attn): LlamaSdpaAttention(\n",
      "                              (q_proj): lora.Linear4bit(\n",
      "                                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                                (lora_dropout): ModuleDict(\n",
      "                                  (default): Dropout(p=0.05, inplace=False)\n",
      "                                )\n",
      "                                (lora_A): ModuleDict(\n",
      "                                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                                )\n",
      "                                (lora_B): ModuleDict(\n",
      "                                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "                                )\n",
      "                                (lora_embedding_A): ParameterDict()\n",
      "                                (lora_embedding_B): ParameterDict()\n",
      "                                (lora_magnitude_vector): ModuleDict()\n",
      "                              )\n",
      "                              (k_proj): lora.Linear4bit(\n",
      "                                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                                (lora_dropout): ModuleDict(\n",
      "                                  (default): Dropout(p=0.05, inplace=False)\n",
      "                                )\n",
      "                                (lora_A): ModuleDict(\n",
      "                                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                                )\n",
      "                                (lora_B): ModuleDict(\n",
      "                                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
      "                                )\n",
      "                                (lora_embedding_A): ParameterDict()\n",
      "                                (lora_embedding_B): ParameterDict()\n",
      "                                (lora_magnitude_vector): ModuleDict()\n",
      "                              )\n",
      "                              (v_proj): lora.Linear4bit(\n",
      "                                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                                (lora_dropout): ModuleDict(\n",
      "                                  (default): Dropout(p=0.05, inplace=False)\n",
      "                                )\n",
      "                                (lora_A): ModuleDict(\n",
      "                                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                                )\n",
      "                                (lora_B): ModuleDict(\n",
      "                                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
      "                                )\n",
      "                                (lora_embedding_A): ParameterDict()\n",
      "                                (lora_embedding_B): ParameterDict()\n",
      "                                (lora_magnitude_vector): ModuleDict()\n",
      "                              )\n",
      "                              (o_proj): lora.Linear4bit(\n",
      "                                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                                (lora_dropout): ModuleDict(\n",
      "                                  (default): Dropout(p=0.05, inplace=False)\n",
      "                                )\n",
      "                                (lora_A): ModuleDict(\n",
      "                                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                                )\n",
      "                                (lora_B): ModuleDict(\n",
      "                                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "                                )\n",
      "                                (lora_embedding_A): ParameterDict()\n",
      "                                (lora_embedding_B): ParameterDict()\n",
      "                                (lora_magnitude_vector): ModuleDict()\n",
      "                              )\n",
      "                              (rotary_emb): LlamaRotaryEmbedding()\n",
      "                            )\n",
      "                            (mlp): LlamaMLP(\n",
      "                              (gate_proj): lora.Linear4bit(\n",
      "                                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                                (lora_dropout): ModuleDict(\n",
      "                                  (default): Dropout(p=0.05, inplace=False)\n",
      "                                )\n",
      "                                (lora_A): ModuleDict(\n",
      "                                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                                )\n",
      "                                (lora_B): ModuleDict(\n",
      "                                  (default): Linear(in_features=8, out_features=14336, bias=False)\n",
      "                                )\n",
      "                                (lora_embedding_A): ParameterDict()\n",
      "                                (lora_embedding_B): ParameterDict()\n",
      "                                (lora_magnitude_vector): ModuleDict()\n",
      "                              )\n",
      "                              (up_proj): lora.Linear4bit(\n",
      "                                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                                (lora_dropout): ModuleDict(\n",
      "                                  (default): Dropout(p=0.05, inplace=False)\n",
      "                                )\n",
      "                                (lora_A): ModuleDict(\n",
      "                                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                                )\n",
      "                                (lora_B): ModuleDict(\n",
      "                                  (default): Linear(in_features=8, out_features=14336, bias=False)\n",
      "                                )\n",
      "                                (lora_embedding_A): ParameterDict()\n",
      "                                (lora_embedding_B): ParameterDict()\n",
      "                                (lora_magnitude_vector): ModuleDict()\n",
      "                              )\n",
      "                              (down_proj): lora.Linear4bit(\n",
      "                                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "                                (lora_dropout): ModuleDict(\n",
      "                                  (default): Dropout(p=0.05, inplace=False)\n",
      "                                )\n",
      "                                (lora_A): ModuleDict(\n",
      "                                  (default): Linear(in_features=14336, out_features=8, bias=False)\n",
      "                                )\n",
      "                                (lora_B): ModuleDict(\n",
      "                                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "                                )\n",
      "                                (lora_embedding_A): ParameterDict()\n",
      "                                (lora_embedding_B): ParameterDict()\n",
      "                                (lora_magnitude_vector): ModuleDict()\n",
      "                              )\n",
      "                              (act_fn): SiLU()\n",
      "                            )\n",
      "                            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "                            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "                          )\n",
      "                        )\n",
      "                        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "                        (rotary_emb): LlamaRotaryEmbedding()\n",
      "                      )\n",
      "                      (lm_head): lora.Linear(\n",
      "                        (base_layer): Linear(in_features=4096, out_features=128256, bias=False)\n",
      "                        (lora_dropout): ModuleDict(\n",
      "                          (default): Dropout(p=0.05, inplace=False)\n",
      "                        )\n",
      "                        (lora_A): ModuleDict(\n",
      "                          (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                        )\n",
      "                        (lora_B): ModuleDict(\n",
      "                          (default): Linear(in_features=8, out_features=128256, bias=False)\n",
      "                        )\n",
      "                        (lora_embedding_A): ParameterDict()\n",
      "                        (lora_embedding_B): ParameterDict()\n",
      "                        (lora_magnitude_vector): ModuleDict()\n",
      "                      )\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c559f449-d619-415c-b3b3-fb7dcc54e6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myinghal\u001b[0m (\u001b[33myinghal-university-of-michigan\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!pip install -q wandb -U\n",
    "\n",
    "import wandb, os\n",
    "wandb.login()\n",
    "\n",
    "wandb_project = \"llama-finetune\"\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "514a9ed3-2bcf-4c20-bdae-f0578c71c548",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b71a5af-c0f0-4754-bae0-1fc99df966b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='651' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 651/1000 6:54:55 < 3:43:07, 0.03 it/s, Epoch 0.26/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.083300</td>\n",
       "      <td>0.945958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.994300</td>\n",
       "      <td>0.916485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.935500</td>\n",
       "      <td>0.892970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.965900</td>\n",
       "      <td>0.882292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.930100</td>\n",
       "      <td>0.873530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.943800</td>\n",
       "      <td>0.867631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.908300</td>\n",
       "      <td>0.863133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.955300</td>\n",
       "      <td>0.859068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.918700</td>\n",
       "      <td>0.855089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.909000</td>\n",
       "      <td>0.851609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.924900</td>\n",
       "      <td>0.848958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.846900</td>\n",
       "      <td>0.847002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='272' max='624' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [272/624 11:09 < 14:29, 0.40 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"llama-finetune\"\n",
    "base_model_name = \"meta-llama/Llama-3.1-8B\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=5,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_checkpointing=True,\n",
    "        gradient_accumulation_steps=4,\n",
    "        max_steps=1000,\n",
    "        learning_rate=2.5e-5,\n",
    "        logging_steps=50,\n",
    "        bf16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_dir=\"./logs\",        # Directory for storing logs\n",
    "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "        save_steps=25,                # Save checkpoints every 50 steps\n",
    "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "        eval_steps=50,               # Evaluate and save checkpoints every 50 steps\n",
    "        do_eval=True,                # Perform evaluation at the end of training\n",
    "        report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63256631-7d11-4d41-8a1a-f150055187ba",
   "metadata": {},
   "source": [
    "Reconnect the kernel after obtaining a good checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf435369-9495-4fc5-a202-0a1373772e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7aeb7ce2f39467b8820cb0db4c96ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"meta-llama/Llama-3.1-8B\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(\n",
    "#    base_model_id,\n",
    "#    quantization_config=bnb_config,  # Same quantization config as before\n",
    "#    device_map=\"auto\",\n",
    "#    trust_remote_code=True,\n",
    "#)\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    quantization_config=bnb_config)\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8223f762-4fe0-48e1-bf42-7f180ea802f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, \"meta-llama/Llama-3.1-8B-llama-finetune/checkpoint-675\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9bac7189-d4b8-4a26-bb5f-74e916aebfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "from deepeval.benchmarks import HellaSwag\n",
    "from deepeval.benchmarks.tasks import HellaSwagTask\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f2b1c1-d9b0-4c3d-9b6f-79a766ec5494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c887ee-ae8c-4fdc-9036-9ebb76248be4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6721ab2-fbe8-4564-8743-efdb62735a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21265c7a-04eb-4473-b5d1-e169f2f6364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Llama3(DeepEvalBaseLLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        tokenizer\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        sections = [section.strip() for section in prompt.split(\"\\n\\n\") if section.strip()]\n",
    "\n",
    "        # Take the last section, including \"Answer:\" for context\n",
    "        prompt = sections[-2]\n",
    "\n",
    "        model = self.load_model()\n",
    "\n",
    "        device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "        model_inputs = self.tokenizer([prompt], return_tensors=\"pt\").to(device)\n",
    "        model.to(device)\n",
    "\n",
    "        generated_ids = model.generate(\n",
    "            **model_inputs, \n",
    "            max_new_tokens=100, \n",
    "            use_cache=True)\n",
    "        \n",
    "        ans = self.tokenizer.batch_decode(generated_ids)[0]\n",
    "\n",
    "        match = re.search(r\"Answer:\\s*([A-D])\", ans)\n",
    "\n",
    "        if match:\n",
    "            answer = match.group(1)\n",
    "        else:\n",
    "            answer = 'N/A'\n",
    "\n",
    "        return answer\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        return self.generate(prompt)\n",
    "\n",
    "    # This is optional.\n",
    "    def batch_generate(self, promtps: list[str]) -> list[str]:\n",
    "        model = self.load_model()\n",
    "        device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "        new_p = []\n",
    "        for p in promtps:\n",
    "            sections = [section.strip() for section in prompt.split(\"\\n\\n\") if section.strip()]\n",
    "            new_p.append(sections[-2])\n",
    "            \n",
    "        model_inputs = self.tokenizer(\n",
    "            new_p,\n",
    "            padding=True,    # Ensure equal-length inputs\n",
    "            truncation=True, # Truncate inputs that exceed max_length\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\").to(device)\n",
    "        model.to(device)\n",
    "\n",
    "        generated_ids = model.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=100, use_cache=True)\n",
    "        decoded_responses = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "        res = []\n",
    "        for ans in decoded_responses:\n",
    "            match = re.search(r\"Answer:\\s*([A-D])\", ans)\n",
    "    \n",
    "            if match:\n",
    "                res.append(match.group(1))\n",
    "            else:\n",
    "                res.append('N/A')\n",
    "        return res\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"Llama 3\"\n",
    "\n",
    "\n",
    "llama3 = Llama3(model=ft_model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "202934b5-e97b-4286-94cc-9b2333ebc96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = HellaSwag(\n",
    "    tasks=[HellaSwagTask.APPLYING_SUNSCREEN, HellaSwagTask.SKATEBOARDING],\n",
    "    n_shots=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "038fe6f2-13b6-4a9b-aa6f-8614d4df42d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Applying sunscreen:   0%|          | 0/20 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Applying sunscreen:   5%|▌         | 1/20 [00:00<00:06,  2.93it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Applying sunscreen:  10%|█         | 2/20 [00:03<00:37,  2.07s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Applying sunscreen:  15%|█▌        | 3/20 [00:03<00:21,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Applying sunscreen:  20%|██        | 4/20 [00:04<00:14,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Applying sunscreen:  25%|██▌       | 5/20 [00:04<00:10,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Applying sunscreen:  30%|███       | 6/20 [00:04<00:07,  1.76it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Applying sunscreen:  35%|███▌      | 7/20 [00:05<00:06,  2.04it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Applying sunscreen:  40%|████      | 8/20 [00:05<00:05,  2.28it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Applying sunscreen:  45%|████▌     | 9/20 [00:05<00:04,  2.47it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Applying sunscreen:  50%|█████     | 10/20 [00:06<00:03,  2.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Applying sunscreen:  55%|█████▌    | 11/20 [00:06<00:03,  2.74it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Applying sunscreen:  60%|██████    | 12/20 [00:06<00:02,  2.82it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Applying sunscreen:  65%|██████▌   | 13/20 [00:07<00:02,  2.86it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Applying sunscreen:  70%|███████   | 14/20 [00:13<00:12,  2.05s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Applying sunscreen:  75%|███████▌  | 15/20 [00:13<00:07,  1.53s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Applying sunscreen:  80%|████████  | 16/20 [00:13<00:04,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Applying sunscreen:  85%|████████▌ | 17/20 [00:14<00:02,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Applying sunscreen:  90%|█████████ | 18/20 [00:14<00:01,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Applying sunscreen:  95%|█████████▌| 19/20 [00:18<00:01,  1.78s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Applying sunscreen: 100%|██████████| 20/20 [00:19<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HellaSwag Task Accuracy (task=Applying sunscreen): 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Skateboarding:   0%|          | 0/9 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Skateboarding:  11%|█         | 1/9 [00:00<00:02,  3.02it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Skateboarding:  22%|██▏       | 2/9 [00:00<00:02,  3.00it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Skateboarding:  33%|███▎      | 3/9 [00:00<00:02,  3.00it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Skateboarding:  44%|████▍     | 4/9 [00:15<00:28,  5.76s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Skateboarding:  56%|█████▌    | 5/9 [00:15<00:15,  3.80s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Skateboarding:  67%|██████▋   | 6/9 [00:15<00:07,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Skateboarding:  78%|███████▊  | 7/9 [00:16<00:03,  1.87s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Skateboarding:  89%|████████▉ | 8/9 [00:16<00:01,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Skateboarding: 100%|██████████| 9/9 [00:16<00:00,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HellaSwag Task Accuracy (task=Skateboarding): 0.3333333333333333\n",
      "Overall HellaSwag Accuracy: 0.4482758620689655\n",
      "Task-specific Scoress:                   Task     Score\n",
      "0  Applying sunscreen  0.500000\n",
      "1       Skateboarding  0.333333\n",
      "Detailed Predictions:                    Task                                              Input  \\\n",
      "0   Applying sunscreen  More and more people begin talking and each of...   \n",
      "1   Applying sunscreen  A woman puts some lotion on her hand. She rubs...   \n",
      "2   Applying sunscreen  Two people are seen hosting a news segment tha...   \n",
      "3   Applying sunscreen  A woman is seen hosting a news segment with se...   \n",
      "4   Applying sunscreen  Various shots shots are shown of people on the...   \n",
      "5   Applying sunscreen  Girls talk in a beach, then girls spray sunscr...   \n",
      "6   Applying sunscreen  Girls talk in a beach, then girls spray sunscr...   \n",
      "7   Applying sunscreen  A medical worker is sitting at a table with a ...   \n",
      "8   Applying sunscreen  He moves a can and touches two other cans. He ...   \n",
      "9   Applying sunscreen  A young lady shows a a beauty cream bottle. th...   \n",
      "10  Applying sunscreen  There is a boy sitting on the bed showing off ...   \n",
      "11  Applying sunscreen  There is a boy sitting on the bed showing off ...   \n",
      "12  Applying sunscreen  The sunburned man is taking his shirt off and ...   \n",
      "13  Applying sunscreen  A woman is shown applying sunscreen to several...   \n",
      "14  Applying sunscreen  A person is seen pumping out sunscreen to kids...   \n",
      "15  Applying sunscreen  Once it is evenly displayed, several paragraph...   \n",
      "16  Applying sunscreen  A bottle of moisturizer is shown. a woman on a...   \n",
      "17  Applying sunscreen  A bottle of moisturizer is shown. A woman on a...   \n",
      "18  Applying sunscreen  A bottle of moisturizer is shown. A woman on a...   \n",
      "19  Applying sunscreen  There are many people in bathing suits standin...   \n",
      "20       Skateboarding  Skaters are skateboarding during the day. now ...   \n",
      "21       Skateboarding  An introduction comes onto the screen for a vi...   \n",
      "22       Skateboarding  An introduction comes onto the screen for a vi...   \n",
      "23       Skateboarding  People are skateboarding down a street. A pers...   \n",
      "24       Skateboarding  Skateboarder to different tricks spinning thei...   \n",
      "25       Skateboarding  Skateboarder to different tricks spinning thei...   \n",
      "26       Skateboarding  Boy is skateboarding in a skate park at night....   \n",
      "27       Skateboarding  He flips the skateboard, and we see it in slow...   \n",
      "28       Skateboarding  A couple of boys are riding skateboards. They ...   \n",
      "\n",
      "   Prediction  Correct  \n",
      "0           A        0  \n",
      "1           C        1  \n",
      "2           D        0  \n",
      "3           A        0  \n",
      "4           C        0  \n",
      "5           A        1  \n",
      "6           A        0  \n",
      "7           B        1  \n",
      "8           A        1  \n",
      "9           B        0  \n",
      "10          A        1  \n",
      "11          B        0  \n",
      "12          B        0  \n",
      "13          C        0  \n",
      "14          C        0  \n",
      "15          B        1  \n",
      "16          A        1  \n",
      "17          B        1  \n",
      "18          C        1  \n",
      "19          B        1  \n",
      "20          A        1  \n",
      "21          C        0  \n",
      "22          C        1  \n",
      "23          B        0  \n",
      "24          D        0  \n",
      "25          C        0  \n",
      "26          C        1  \n",
      "27          B        0  \n",
      "28          C        0  \n",
      "0.4482758620689655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = benchmark.evaluate(model=llama3, batch_size = 5)\n",
    "print(\"Task-specific Scoress: \", benchmark.task_scores)\n",
    "print(\"Detailed Predictions: \", benchmark.predictions)\n",
    "print(benchmark.overall_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
